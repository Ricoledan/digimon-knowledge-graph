{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 06: Centrality & Influence Analysis\n",
    "\n",
    "**Objective**: Identify the most important and influential Digimon in the knowledge graph.\n",
    "\n",
    "This notebook explores:\n",
    "- Various centrality measures (degree, betweenness, closeness, eigenvector, PageRank)\n",
    "- Custom influence metrics\n",
    "- Comparative analysis of centrality measures\n",
    "- Visualization of influential nodes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    Neo4jConnector,\n",
    "    calculate_centrality_measures,\n",
    "    plot_centrality_comparison,\n",
    "    plot_network_static,\n",
    "    save_figure,\n",
    "    TYPE_COLORS, LEVEL_COLORS, ATTRIBUTE_COLORS\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Network Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = Neo4jConnector()\n",
    "print(\"Connected to Neo4j database\")\n",
    "\n",
    "# Get all data\n",
    "digimon_df = conn.get_all_digimon()\n",
    "evolution_data = conn.get_evolution_chains()\n",
    "moves_df = conn.get_digimon_moves()\n",
    "\n",
    "print(f\"\\nLoaded data:\")\n",
    "print(f\"  - {len(digimon_df)} Digimon\")\n",
    "print(f\"  - {len(evolution_data)} evolution relationships\")\n",
    "print(f\"  - {len(moves_df)} move relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multiple network representations\n",
    "\n",
    "# 1. Evolution Network (Directed)\n",
    "evolution_graph = nx.DiGraph()\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    evolution_graph.add_node(\n",
    "        digimon['name_en'],\n",
    "        level=digimon['level'],\n",
    "        type=digimon['type'],\n",
    "        attribute=digimon['attribute']\n",
    "    )\n",
    "\n",
    "for evo in evolution_data:\n",
    "    if evo['from_digimon'] in evolution_graph and evo['to_digimon'] in evolution_graph:\n",
    "        evolution_graph.add_edge(evo['from_digimon'], evo['to_digimon'])\n",
    "\n",
    "print(f\"Evolution network: {evolution_graph.number_of_nodes()} nodes, {evolution_graph.number_of_edges()} edges\")\n",
    "\n",
    "# 2. Similarity Network (Undirected) - based on shared attributes\n",
    "similarity_graph = nx.Graph()\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    similarity_graph.add_node(\n",
    "        digimon['name_en'],\n",
    "        level=digimon['level'],\n",
    "        type=digimon['type'],\n",
    "        attribute=digimon['attribute']\n",
    "    )\n",
    "\n",
    "# Add edges for shared types (sample for efficiency)\n",
    "type_groups = digimon_df.groupby('type')['name_en'].apply(list)\n",
    "for type_name, digimon_list in type_groups.items():\n",
    "    if 2 <= len(digimon_list) <= 30:  # Reasonable group sizes\n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, min(i + 5, len(digimon_list))):\n",
    "                similarity_graph.add_edge(digimon_list[i], digimon_list[j], weight=1.0)\n",
    "\n",
    "# Add edges for shared moves\n",
    "move_groups = moves_df.groupby('move')['digimon'].apply(list)\n",
    "for move, digimon_list in move_groups.items():\n",
    "    if 2 <= len(digimon_list) <= 10:  # Rare moves only\n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, len(digimon_list)):\n",
    "                if digimon_list[i] in similarity_graph and digimon_list[j] in similarity_graph:\n",
    "                    if similarity_graph.has_edge(digimon_list[i], digimon_list[j]):\n",
    "                        similarity_graph[digimon_list[i]][digimon_list[j]]['weight'] += 0.5\n",
    "                    else:\n",
    "                        similarity_graph.add_edge(digimon_list[i], digimon_list[j], weight=0.5)\n",
    "\n",
    "print(f\"Similarity network: {similarity_graph.number_of_nodes()} nodes, {similarity_graph.number_of_edges()} edges\")\n",
    "\n",
    "# 3. Combined Network (for comprehensive analysis)\n",
    "combined_graph = nx.Graph()\n",
    "# Add all nodes\n",
    "for node, attrs in evolution_graph.nodes(data=True):\n",
    "    combined_graph.add_node(node, **attrs)\n",
    "# Add evolution edges\n",
    "for u, v in evolution_graph.edges():\n",
    "    combined_graph.add_edge(u, v, weight=2.0, type='evolution')\n",
    "# Add similarity edges\n",
    "for u, v, data in similarity_graph.edges(data=True):\n",
    "    if combined_graph.has_edge(u, v):\n",
    "        combined_graph[u][v]['weight'] += data['weight']\n",
    "    else:\n",
    "        combined_graph.add_edge(u, v, weight=data['weight'], type='similarity')\n",
    "\n",
    "print(f\"Combined network: {combined_graph.number_of_nodes()} nodes, {combined_graph.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality for evolution network\n",
    "print(\"=== EVOLUTION NETWORK CENTRALITY ===\")\n",
    "evolution_centrality = calculate_centrality_measures(evolution_graph)\n",
    "evolution_centrality = evolution_centrality.sort_values('degree', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 by degree centrality (most evolution connections):\")\n",
    "for idx, row in evolution_centrality.head(10).iterrows():\n",
    "    in_deg = evolution_graph.in_degree(idx) if idx in evolution_graph else 0\n",
    "    out_deg = evolution_graph.out_degree(idx) if idx in evolution_graph else 0\n",
    "    print(f\"  {idx}: in={in_deg}, out={out_deg}, total={in_deg+out_deg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality for similarity network\n",
    "print(\"\\n=== SIMILARITY NETWORK CENTRALITY ===\")\n",
    "similarity_centrality = calculate_centrality_measures(similarity_graph)\n",
    "similarity_centrality = similarity_centrality.sort_values('degree', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 by degree centrality (most similar Digimon):\")\n",
    "for idx, row in similarity_centrality.head(10).iterrows():\n",
    "    degree = similarity_graph.degree(idx)\n",
    "    node_data = similarity_graph.nodes[idx]\n",
    "    print(f\"  {idx} ({node_data['type']}/{node_data['attribute']}): {degree} connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality for combined network\n",
    "print(\"\\n=== COMBINED NETWORK CENTRALITY ===\")\n",
    "combined_centrality = calculate_centrality_measures(combined_graph)\n",
    "\n",
    "# Add node attributes to centrality DataFrame\n",
    "for node in combined_centrality.index:\n",
    "    if node in combined_graph:\n",
    "        attrs = combined_graph.nodes[node]\n",
    "        combined_centrality.loc[node, 'type'] = attrs.get('type', 'Unknown')\n",
    "        combined_centrality.loc[node, 'level'] = attrs.get('level', 'Unknown')\n",
    "        combined_centrality.loc[node, 'attribute'] = attrs.get('attribute', 'Unknown')\n",
    "\n",
    "print(\"\\nCentrality measures calculated for all networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Influence Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate custom influence scores\n",
    "influence_scores = pd.DataFrame(index=combined_centrality.index)\n",
    "\n",
    "# 1. Evolution Influence Score\n",
    "# Higher score for Digimon that are central in evolution chains\n",
    "for node in influence_scores.index:\n",
    "    if node in evolution_graph:\n",
    "        ancestors = len(nx.ancestors(evolution_graph, node))\n",
    "        descendants = len(nx.descendants(evolution_graph, node))\n",
    "        evolution_influence = (ancestors + descendants * 2) / evolution_graph.number_of_nodes()\n",
    "    else:\n",
    "        evolution_influence = 0\n",
    "    influence_scores.loc[node, 'evolution_influence'] = evolution_influence\n",
    "\n",
    "# 2. Type Diversity Index\n",
    "# Score based on connections to different types\n",
    "for node in influence_scores.index:\n",
    "    if node in combined_graph:\n",
    "        neighbor_types = set()\n",
    "        for neighbor in combined_graph.neighbors(node):\n",
    "            neighbor_type = combined_graph.nodes[neighbor].get('type', 'Unknown')\n",
    "            neighbor_types.add(neighbor_type)\n",
    "        type_diversity = len(neighbor_types) / digimon_df['type'].nunique()\n",
    "    else:\n",
    "        type_diversity = 0\n",
    "    influence_scores.loc[node, 'type_diversity'] = type_diversity\n",
    "\n",
    "# 3. Move Uniqueness Score\n",
    "# Higher score for Digimon with rare moves\n",
    "move_counts = moves_df['move'].value_counts()\n",
    "for node in influence_scores.index:\n",
    "    node_moves = moves_df[moves_df['digimon'] == node]['move'].tolist()\n",
    "    if node_moves:\n",
    "        # Calculate average rarity of moves (inverse of frequency)\n",
    "        move_rarities = [1 / move_counts[move] for move in node_moves]\n",
    "        move_uniqueness = np.mean(move_rarities) * 100\n",
    "    else:\n",
    "        move_uniqueness = 0\n",
    "    influence_scores.loc[node, 'move_uniqueness'] = move_uniqueness\n",
    "\n",
    "# 4. Combined Influence Score\n",
    "# Weighted combination of all metrics\n",
    "influence_scores['combined_influence'] = (\n",
    "    combined_centrality['degree'] * 0.2 +\n",
    "    combined_centrality['betweenness'] * 0.2 +\n",
    "    combined_centrality['eigenvector'] * 0.2 +\n",
    "    combined_centrality['pagerank'] * 100 * 0.2 +\n",
    "    influence_scores['evolution_influence'] * 0.1 +\n",
    "    influence_scores['type_diversity'] * 0.05 +\n",
    "    influence_scores['move_uniqueness'] * 0.05\n",
    ")\n",
    "\n",
    "# Normalize to 0-1 scale\n",
    "for col in influence_scores.columns:\n",
    "    if influence_scores[col].max() > 0:\n",
    "        influence_scores[col] = influence_scores[col] / influence_scores[col].max()\n",
    "\n",
    "print(\"Custom influence metrics calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics\n",
    "all_metrics = pd.concat([combined_centrality, influence_scores], axis=1)\n",
    "all_metrics = all_metrics.sort_values('combined_influence', ascending=False)\n",
    "\n",
    "print(\"=== TOP 20 MOST INFLUENTIAL DIGIMON ===\")\n",
    "print(\"\\nRank | Digimon | Type | Level | Combined Score\")\n",
    "print(\"-\" * 60)\n",
    "for i, (idx, row) in enumerate(all_metrics.head(20).iterrows()):\n",
    "    print(f\"{i+1:4d} | {idx:20s} | {row['type']:15s} | {row['level']:10s} | {row['combined_influence']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between centrality measures\n",
    "centrality_cols = ['degree', 'betweenness', 'closeness', 'eigenvector', 'pagerank']\n",
    "correlation_matrix = combined_centrality[centrality_cols].corr(method='spearman')\n",
    "\n",
    "print(\"=== CENTRALITY MEASURE CORRELATIONS ===\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=ax)\n",
    "ax.set_title('Centrality Measure Correlations (Spearman)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"centrality_correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking stability analysis\n",
    "# Compare top-k rankings across different measures\n",
    "k = 50\n",
    "ranking_overlap = pd.DataFrame(index=centrality_cols, columns=centrality_cols)\n",
    "\n",
    "for measure1 in centrality_cols:\n",
    "    top_k1 = set(combined_centrality.nlargest(k, measure1).index)\n",
    "    for measure2 in centrality_cols:\n",
    "        top_k2 = set(combined_centrality.nlargest(k, measure2).index)\n",
    "        overlap = len(top_k1 & top_k2) / k\n",
    "        ranking_overlap.loc[measure1, measure2] = overlap\n",
    "\n",
    "# Convert to numeric\n",
    "ranking_overlap = ranking_overlap.astype(float)\n",
    "\n",
    "print(f\"\\n=== TOP-{k} RANKING OVERLAP ===\")\n",
    "print(ranking_overlap.round(2))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(ranking_overlap, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "            vmin=0, vmax=1, square=True, ax=ax)\n",
    "ax.set_title(f'Top-{k} Ranking Overlap Between Measures', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"ranking_overlap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality by level analysis\n",
    "level_centrality = all_metrics.groupby('level')[centrality_cols].mean()\n",
    "level_order = ['Baby', 'In-Training', 'Rookie', 'Champion', 'Ultimate', 'Mega', 'Ultra']\n",
    "level_centrality = level_centrality.reindex(level_order, fill_value=0)\n",
    "\n",
    "print(\"\\n=== AVERAGE CENTRALITY BY LEVEL ===\")\n",
    "print(level_centrality.round(3))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "level_centrality.plot(kind='bar', ax=ax, colormap='viridis')\n",
    "ax.set_xlabel('Level')\n",
    "ax.set_ylabel('Average Centrality Score')\n",
    "ax.set_title('Centrality Measures by Evolution Level', fontsize=16, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"centrality_by_level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top influential Digimon radar chart\n",
    "top_n = 10\n",
    "top_digimon = all_metrics.head(top_n)\n",
    "\n",
    "# Prepare data for radar chart\n",
    "metrics_for_radar = ['degree', 'betweenness', 'eigenvector', 'pagerank', \n",
    "                    'evolution_influence', 'type_diversity']\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=5,\n",
    "    subplot_titles=[name for name in top_digimon.index[:10]],\n",
    "    specs=[[{'type': 'polar'}] * 5] * 2\n",
    ")\n",
    "\n",
    "for idx, (digimon_name, scores) in enumerate(top_digimon.iterrows()):\n",
    "    if idx >= 10:\n",
    "        break\n",
    "    \n",
    "    row = idx // 5 + 1\n",
    "    col = idx % 5 + 1\n",
    "    \n",
    "    values = [scores[metric] for metric in metrics_for_radar]\n",
    "    values.append(values[0])  # Close the polygon\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatterpolar(\n",
    "            r=values,\n",
    "            theta=metrics_for_radar + [metrics_for_radar[0]],\n",
    "            fill='toself',\n",
    "            name=digimon_name\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    title_text=\"Top 10 Influential Digimon - Centrality Profiles\",\n",
    "    height=800\n",
    ")\n",
    "\n",
    "save_figure(fig, \"top_digimon_radar_charts\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality distribution plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, measure in enumerate(centrality_cols + ['combined_influence']):\n",
    "    ax = axes[i]\n",
    "    data = all_metrics[measure].dropna()\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax.hist(data, bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel(measure.replace('_', ' ').title())\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{measure.replace(\"_\", \" \").title()} Distribution', fontweight='bold')\n",
    "    \n",
    "    # Add statistics\n",
    "    ax.axvline(data.mean(), color='red', linestyle='--', label=f'Mean: {data.mean():.3f}')\n",
    "    ax.axvline(data.median(), color='green', linestyle='--', label=f'Median: {data.median():.3f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Log scale for better visualization\n",
    "    if measure in ['betweenness', 'degree']:\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"centrality_distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network visualization with node size by centrality\n",
    "# Create subgraph of most central nodes\n",
    "top_nodes = all_metrics.head(100).index.tolist()\n",
    "central_subgraph = combined_graph.subgraph(top_nodes).copy()\n",
    "\n",
    "# Set node sizes based on combined influence\n",
    "node_sizes = []\n",
    "node_colors = []\n",
    "for node in central_subgraph.nodes():\n",
    "    size = all_metrics.loc[node, 'combined_influence'] * 1000 + 100\n",
    "    node_sizes.append(size)\n",
    "    \n",
    "    # Color by level\n",
    "    level = central_subgraph.nodes[node].get('level', 'Unknown')\n",
    "    color = LEVEL_COLORS.get(level, '#808080')\n",
    "    node_colors.append(color)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "pos = nx.spring_layout(central_subgraph, k=3, iterations=50)\n",
    "\n",
    "# Draw network\n",
    "nx.draw_networkx_nodes(central_subgraph, pos, node_size=node_sizes, \n",
    "                      node_color=node_colors, alpha=0.8, ax=ax)\n",
    "nx.draw_networkx_edges(central_subgraph, pos, alpha=0.2, ax=ax)\n",
    "\n",
    "# Add labels for top nodes\n",
    "top_20 = all_metrics.head(20).index\n",
    "labels = {node: node for node in top_20 if node in central_subgraph}\n",
    "nx.draw_networkx_labels(central_subgraph, pos, labels, font_size=8, ax=ax)\n",
    "\n",
    "ax.set_title('Network of Most Influential Digimon\\n(Node size = influence, Color = level)', \n",
    "            fontsize=20, fontweight='bold', pad=20)\n",
    "ax.axis('off')\n",
    "\n",
    "# Add legend for levels\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, label=level) \n",
    "                  for level, color in LEVEL_COLORS.items()]\n",
    "ax.legend(handles=legend_elements, loc='upper right', title='Level')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"influential_digimon_network\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influence by type analysis\n",
    "type_influence = all_metrics.groupby('type')['combined_influence'].agg(['mean', 'max', 'count'])\n",
    "type_influence = type_influence[type_influence['count'] >= 5]  # Types with at least 5 Digimon\n",
    "type_influence = type_influence.sort_values('mean', ascending=False).head(20)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Average influence by type\n",
    "colors = [TYPE_COLORS.get(t, '#808080') for t in type_influence.index]\n",
    "bars1 = ax1.barh(range(len(type_influence)), type_influence['mean'], color=colors)\n",
    "ax1.set_yticks(range(len(type_influence)))\n",
    "ax1.set_yticklabels(type_influence.index)\n",
    "ax1.set_xlabel('Average Combined Influence')\n",
    "ax1.set_title('Average Influence by Type (Top 20)', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars1):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "# Max influence by type\n",
    "bars2 = ax2.barh(range(len(type_influence)), type_influence['max'], color=colors)\n",
    "ax2.set_yticks(range(len(type_influence)))\n",
    "ax2.set_yticklabels(type_influence.index)\n",
    "ax2.set_xlabel('Maximum Combined Influence')\n",
    "ax2.set_title('Maximum Influence by Type (Top 20)', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars2):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"influence_by_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITS analysis (Hubs and Authorities) for evolution network\n",
    "hits_h, hits_a = nx.hits(evolution_graph, max_iter=100)\n",
    "\n",
    "# Convert to DataFrames\n",
    "hubs_df = pd.DataFrame.from_dict(hits_h, orient='index', columns=['hub_score'])\n",
    "authorities_df = pd.DataFrame.from_dict(hits_a, orient='index', columns=['authority_score'])\n",
    "hits_df = pd.concat([hubs_df, authorities_df], axis=1)\n",
    "hits_df = hits_df.sort_values('hub_score', ascending=False)\n",
    "\n",
    "print(\"=== EVOLUTION NETWORK HUBS AND AUTHORITIES ===\")\n",
    "print(\"\\nTop 10 Hubs (evolve into many):\")\n",
    "for idx, score in hits_df.head(10)['hub_score'].items():\n",
    "    out_deg = evolution_graph.out_degree(idx)\n",
    "    print(f\"  {idx}: hub_score={score:.3f}, out_degree={out_deg}\")\n",
    "\n",
    "print(\"\\nTop 10 Authorities (evolved from many):\")\n",
    "hits_df_auth = hits_df.sort_values('authority_score', ascending=False)\n",
    "for idx, score in hits_df_auth.head(10)['authority_score'].items():\n",
    "    in_deg = evolution_graph.in_degree(idx)\n",
    "    print(f\"  {idx}: authority_score={score:.3f}, in_degree={in_deg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare export data\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_dir = Path('../results/data')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export centrality scores\n",
    "all_metrics.to_csv(results_dir / 'centrality_scores.csv')\n",
    "\n",
    "# Export top influential Digimon\n",
    "top_100_influential = all_metrics.head(100)[['type', 'level', 'attribute', 'combined_influence'] + centrality_cols]\n",
    "top_100_influential.to_csv(results_dir / 'top_100_influential_digimon.csv')\n",
    "\n",
    "# Export HITS scores\n",
    "hits_df.to_csv(results_dir / 'evolution_hubs_authorities.csv')\n",
    "\n",
    "# Export summary statistics\n",
    "centrality_summary = {\n",
    "    'total_analyzed': int(len(all_metrics)),\n",
    "    'networks_analyzed': {\n",
    "        'evolution': {'nodes': evolution_graph.number_of_nodes(), \n",
    "                     'edges': evolution_graph.number_of_edges()},\n",
    "        'similarity': {'nodes': similarity_graph.number_of_nodes(), \n",
    "                       'edges': similarity_graph.number_of_edges()},\n",
    "        'combined': {'nodes': combined_graph.number_of_nodes(), \n",
    "                    'edges': combined_graph.number_of_edges()}\n",
    "    },\n",
    "    'most_influential': {\n",
    "        'overall': all_metrics.index[0],\n",
    "        'by_degree': combined_centrality.idxmax()['degree'],\n",
    "        'by_betweenness': combined_centrality.idxmax()['betweenness'],\n",
    "        'by_eigenvector': combined_centrality.idxmax()['eigenvector'],\n",
    "        'by_pagerank': combined_centrality.idxmax()['pagerank']\n",
    "    },\n",
    "    'centrality_correlations': correlation_matrix.to_dict(),\n",
    "    'average_scores': {\n",
    "        metric: float(all_metrics[metric].mean()) \n",
    "        for metric in centrality_cols + ['combined_influence']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(results_dir / 'centrality_summary.json', 'w') as f:\n",
    "    json.dump(centrality_summary, f, indent=2)\n",
    "\n",
    "print(\"Centrality analysis results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Centrality & Influence Insights:\n",
    "\n",
    "1. **Influential Digimon**:\n",
    "   - Clear hierarchy of influence exists in the network\n",
    "   - Top influential Digimon often serve as evolution hubs\n",
    "   - Different centrality measures capture different aspects of importance\n",
    "\n",
    "2. **Centrality Patterns**:\n",
    "   - Strong correlation between degree and eigenvector centrality\n",
    "   - Betweenness identifies bridge Digimon between communities\n",
    "   - PageRank effectively identifies globally important nodes\n",
    "\n",
    "3. **Level and Type Effects**:\n",
    "   - Middle evolution levels (Champion, Ultimate) show highest average centrality\n",
    "   - Certain types naturally have higher influence due to popularity\n",
    "   - Evolution patterns create natural hierarchies\n",
    "\n",
    "4. **Network Roles**:\n",
    "   - Hubs: Digimon that evolve into many forms\n",
    "   - Authorities: Popular evolution targets\n",
    "   - Bridges: Connect different parts of the network\n",
    "\n",
    "These insights reveal the power structure and influence dynamics within the Digimon universe, with implications for game balance and narrative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Centrality & influence analysis complete! Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}