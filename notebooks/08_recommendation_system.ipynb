{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 08: Similarity & Recommendation System\n",
    "\n",
    "**Objective**: Build a Digimon recommendation system based on multiple similarity metrics.\n",
    "\n",
    "This notebook implements:\n",
    "- Multiple similarity metrics (attributes, moves, graph distance, embeddings)\n",
    "- Content-based filtering recommendations\n",
    "- Evolution path recommendations\n",
    "- Team composition recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform, jaccard\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    Neo4jConnector,\n",
    "    calculate_centrality_measures,\n",
    "    save_figure,\n",
    "    TYPE_COLORS, ATTRIBUTE_COLORS, LEVEL_COLORS\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Build Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = Neo4jConnector()\n",
    "print(\"Connected to Neo4j database\")\n",
    "\n",
    "# Load all data\n",
    "digimon_df = conn.get_all_digimon()\n",
    "evolution_data = conn.get_evolution_chains()\n",
    "moves_df = conn.get_digimon_moves()\n",
    "\n",
    "print(f\"\\nLoaded data:\")\n",
    "print(f\"  - {len(digimon_df)} Digimon\")\n",
    "print(f\"  - {len(evolution_data)} evolution relationships\")\n",
    "print(f\"  - {len(moves_df)} move relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive feature matrix\n",
    "print(\"\\n=== BUILDING FEATURE MATRIX ===\")\n",
    "\n",
    "# Start with basic attributes\n",
    "features_df = digimon_df[['name_en', 'level', 'type', 'attribute']].copy()\n",
    "features_df.set_index('name_en', inplace=True)\n",
    "\n",
    "# 1. One-hot encode categorical features\n",
    "# Type encoding (keep top 30 types)\n",
    "top_types = digimon_df['type'].value_counts().head(30).index\n",
    "for t in top_types:\n",
    "    features_df[f'type_{t}'] = (features_df['type'] == t).astype(int)\n",
    "\n",
    "# Attribute encoding\n",
    "for attr in ['Vaccine', 'Virus', 'Data', 'Free']:\n",
    "    features_df[f'attr_{attr}'] = (features_df['attribute'] == attr).astype(int)\n",
    "\n",
    "# Level encoding\n",
    "level_order = {'Baby': 0, 'In-Training': 1, 'Rookie': 2, 'Champion': 3, \n",
    "               'Ultimate': 4, 'Mega': 5, 'Ultra': 6}\n",
    "features_df['level_numeric'] = features_df['level'].map(level_order).fillna(3)\n",
    "\n",
    "# 2. Move-based features\n",
    "print(\"Adding move-based features...\")\n",
    "# Create move matrix for each Digimon\n",
    "move_matrix = moves_df.pivot_table(\n",
    "    index='digimon', \n",
    "    columns='move', \n",
    "    values='move',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "# Keep only moves that appear in at least 5 Digimon\n",
    "common_moves = move_matrix.columns[move_matrix.sum() >= 5]\n",
    "move_matrix = move_matrix[common_moves]\n",
    "\n",
    "# Add move features\n",
    "features_df = features_df.join(move_matrix, how='left').fillna(0)\n",
    "\n",
    "# 3. Graph-based features\n",
    "print(\"Adding graph-based features...\")\n",
    "# Build graph\n",
    "G = nx.Graph()\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    G.add_node(digimon['name_en'])\n",
    "\n",
    "# Add evolution edges\n",
    "for evo in evolution_data:\n",
    "    if evo['from_digimon'] in G and evo['to_digimon'] in G:\n",
    "        G.add_edge(evo['from_digimon'], evo['to_digimon'])\n",
    "\n",
    "# Calculate centrality measures\n",
    "centrality_df = calculate_centrality_measures(G)\n",
    "features_df = features_df.join(centrality_df[['degree', 'betweenness', 'eigenvector']], \n",
    "                               how='left').fillna(0)\n",
    "\n",
    "# 4. Evolution statistics\n",
    "evolution_df = pd.DataFrame(evolution_data)\n",
    "in_degree = evolution_df.groupby('to_digimon').size()\n",
    "out_degree = evolution_df.groupby('from_digimon').size()\n",
    "features_df['evolution_in'] = features_df.index.map(in_degree).fillna(0)\n",
    "features_df['evolution_out'] = features_df.index.map(out_degree).fillna(0)\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {features_df.shape}\")\n",
    "print(f\"Features include: categorical encodings, {len(common_moves)} moves, graph metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Similarity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare numeric features only\n",
    "numeric_features = features_df.select_dtypes(include=[np.number]).columns\n",
    "feature_matrix = features_df[numeric_features].fillna(0)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "feature_matrix_scaled = scaler.fit_transform(feature_matrix)\n",
    "feature_matrix_scaled = pd.DataFrame(\n",
    "    feature_matrix_scaled, \n",
    "    index=feature_matrix.index, \n",
    "    columns=feature_matrix.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cosine Similarity (overall features)\n",
    "print(\"=== CALCULATING SIMILARITY MATRICES ===\")\n",
    "print(\"\\n1. Cosine similarity...\")\n",
    "cosine_sim = cosine_similarity(feature_matrix_scaled)\n",
    "cosine_sim_df = pd.DataFrame(\n",
    "    cosine_sim,\n",
    "    index=feature_matrix.index,\n",
    "    columns=feature_matrix.index\n",
    ")\n",
    "\n",
    "# 2. Move-based Jaccard Similarity\n",
    "print(\"2. Move-based Jaccard similarity...\")\n",
    "move_features = [col for col in feature_matrix.columns if col in common_moves]\n",
    "move_matrix_binary = (feature_matrix[move_features] > 0).astype(int)\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "jaccard_sim = np.zeros((len(move_matrix_binary), len(move_matrix_binary)))\n",
    "for i in range(len(move_matrix_binary)):\n",
    "    for j in range(i, len(move_matrix_binary)):\n",
    "        if i == j:\n",
    "            jaccard_sim[i, j] = 1.0\n",
    "        else:\n",
    "            vec1 = move_matrix_binary.iloc[i].values\n",
    "            vec2 = move_matrix_binary.iloc[j].values\n",
    "            if vec1.sum() == 0 and vec2.sum() == 0:\n",
    "                similarity = 0\n",
    "            else:\n",
    "                similarity = 1 - jaccard(vec1, vec2)\n",
    "            jaccard_sim[i, j] = similarity\n",
    "            jaccard_sim[j, i] = similarity\n",
    "\n",
    "jaccard_sim_df = pd.DataFrame(\n",
    "    jaccard_sim,\n",
    "    index=feature_matrix.index,\n",
    "    columns=feature_matrix.index\n",
    ")\n",
    "\n",
    "# 3. Type-Attribute Similarity\n",
    "print(\"3. Type-Attribute similarity...\")\n",
    "type_attr_features = [col for col in feature_matrix.columns \n",
    "                     if col.startswith('type_') or col.startswith('attr_')]\n",
    "type_attr_sim = cosine_similarity(feature_matrix[type_attr_features])\n",
    "type_attr_sim_df = pd.DataFrame(\n",
    "    type_attr_sim,\n",
    "    index=feature_matrix.index,\n",
    "    columns=feature_matrix.index\n",
    ")\n",
    "\n",
    "# 4. Graph Distance Similarity\n",
    "print(\"4. Graph distance similarity...\")\n",
    "# Calculate shortest path distances (sample for efficiency)\n",
    "sample_size = min(500, len(G.nodes()))\n",
    "sample_nodes = list(G.nodes())[:sample_size]\n",
    "\n",
    "graph_distances = {}\n",
    "for node in sample_nodes:\n",
    "    if node in G:\n",
    "        distances = nx.single_source_shortest_path_length(G, node, cutoff=5)\n",
    "        graph_distances[node] = distances\n",
    "\n",
    "# Convert to similarity (inverse of distance)\n",
    "graph_sim = np.zeros((len(sample_nodes), len(sample_nodes)))\n",
    "for i, node1 in enumerate(sample_nodes):\n",
    "    for j, node2 in enumerate(sample_nodes):\n",
    "        if node1 in graph_distances and node2 in graph_distances[node1]:\n",
    "            distance = graph_distances[node1][node2]\n",
    "            graph_sim[i, j] = 1 / (1 + distance)\n",
    "        elif i == j:\n",
    "            graph_sim[i, j] = 1.0\n",
    "        else:\n",
    "            graph_sim[i, j] = 0.0\n",
    "\n",
    "graph_sim_df = pd.DataFrame(\n",
    "    graph_sim,\n",
    "    index=sample_nodes,\n",
    "    columns=sample_nodes\n",
    ")\n",
    "\n",
    "print(\"\\nSimilarity matrices calculated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommendation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_digimon(digimon_name, similarity_matrix, top_k=10, exclude_self=True):\n",
    "    \"\"\"\n",
    "    Find most similar Digimon based on given similarity matrix.\n",
    "    \"\"\"\n",
    "    if digimon_name not in similarity_matrix.index:\n",
    "        return f\"Digimon '{digimon_name}' not found in database.\"\n",
    "    \n",
    "    # Get similarity scores\n",
    "    similarities = similarity_matrix.loc[digimon_name].sort_values(ascending=False)\n",
    "    \n",
    "    # Exclude self if requested\n",
    "    if exclude_self:\n",
    "        similarities = similarities[similarities.index != digimon_name]\n",
    "    \n",
    "    # Get top K\n",
    "    recommendations = similarities.head(top_k)\n",
    "    \n",
    "    # Add metadata\n",
    "    result = []\n",
    "    for rec_name, score in recommendations.items():\n",
    "        if rec_name in digimon_df.set_index('name_en').index:\n",
    "            digimon_info = digimon_df.set_index('name_en').loc[rec_name]\n",
    "            result.append({\n",
    "                'name': rec_name,\n",
    "                'similarity': score,\n",
    "                'type': digimon_info['type'],\n",
    "                'attribute': digimon_info['attribute'],\n",
    "                'level': digimon_info['level']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def recommend_evolution_path(digimon_name, evolution_graph, digimon_data):\n",
    "    \"\"\"\n",
    "    Recommend optimal evolution paths for a Digimon.\n",
    "    \"\"\"\n",
    "    if digimon_name not in evolution_graph:\n",
    "        return f\"Digimon '{digimon_name}' not found in evolution graph.\"\n",
    "    \n",
    "    # Get current Digimon info\n",
    "    current_info = digimon_data[digimon_data['name_en'] == digimon_name].iloc[0]\n",
    "    current_level = current_info['level']\n",
    "    \n",
    "    # Find all possible evolutions\n",
    "    descendants = nx.descendants(evolution_graph, digimon_name)\n",
    "    \n",
    "    # Find paths to each descendant\n",
    "    evolution_paths = []\n",
    "    for descendant in descendants:\n",
    "        try:\n",
    "            paths = list(nx.all_simple_paths(evolution_graph, digimon_name, descendant, cutoff=5))\n",
    "            for path in paths:\n",
    "                # Calculate path score based on final Digimon's attributes\n",
    "                final_digimon = digimon_data[digimon_data['name_en'] == path[-1]].iloc[0]\n",
    "                \n",
    "                # Score based on level progression and popularity (degree)\n",
    "                level_score = level_order.get(final_digimon['level'], 0)\n",
    "                popularity_score = evolution_graph.degree(path[-1])\n",
    "                \n",
    "                evolution_paths.append({\n",
    "                    'path': ' → '.join(path),\n",
    "                    'length': len(path) - 1,\n",
    "                    'final_digimon': path[-1],\n",
    "                    'final_level': final_digimon['level'],\n",
    "                    'final_type': final_digimon['type'],\n",
    "                    'score': level_score + popularity_score * 0.1\n",
    "                })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Sort by score and return top paths\n",
    "    evolution_df = pd.DataFrame(evolution_paths)\n",
    "    if len(evolution_df) > 0:\n",
    "        return evolution_df.sort_values('score', ascending=False).head(10)\n",
    "    else:\n",
    "        return \"No evolution paths found for this Digimon.\"\n",
    "\n",
    "\n",
    "def recommend_team_composition(current_team, all_digimon, similarity_matrix, \n",
    "                             diversity_weight=0.7, synergy_weight=0.3):\n",
    "    \"\"\"\n",
    "    Recommend Digimon to add to a team for balanced composition.\n",
    "    \"\"\"\n",
    "    if not current_team:\n",
    "        return \"Please provide at least one Digimon in the current team.\"\n",
    "    \n",
    "    # Get current team attributes\n",
    "    team_data = all_digimon[all_digimon['name_en'].isin(current_team)]\n",
    "    team_types = team_data['type'].value_counts()\n",
    "    team_attributes = team_data['attribute'].value_counts()\n",
    "    team_levels = team_data['level'].value_counts()\n",
    "    \n",
    "    # Find candidates (exclude current team)\n",
    "    candidates = all_digimon[~all_digimon['name_en'].isin(current_team)]\n",
    "    \n",
    "    recommendations = []\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        candidate_name = candidate['name_en']\n",
    "        \n",
    "        # Diversity score (prefer different types/attributes)\n",
    "        type_diversity = 1.0 if candidate['type'] not in team_types else 0.2\n",
    "        attr_diversity = 1.0 if candidate['attribute'] not in team_attributes else 0.5\n",
    "        diversity_score = (type_diversity + attr_diversity) / 2\n",
    "        \n",
    "        # Synergy score (average similarity to team members)\n",
    "        if candidate_name in similarity_matrix.index:\n",
    "            synergies = []\n",
    "            for team_member in current_team:\n",
    "                if team_member in similarity_matrix.columns:\n",
    "                    synergies.append(similarity_matrix.loc[candidate_name, team_member])\n",
    "            synergy_score = np.mean(synergies) if synergies else 0\n",
    "        else:\n",
    "            synergy_score = 0\n",
    "        \n",
    "        # Combined score\n",
    "        total_score = diversity_weight * diversity_score + synergy_weight * synergy_score\n",
    "        \n",
    "        recommendations.append({\n",
    "            'name': candidate_name,\n",
    "            'type': candidate['type'],\n",
    "            'attribute': candidate['attribute'],\n",
    "            'level': candidate['level'],\n",
    "            'diversity_score': diversity_score,\n",
    "            'synergy_score': synergy_score,\n",
    "            'total_score': total_score\n",
    "        })\n",
    "    \n",
    "    # Sort and return top recommendations\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    return recommendations_df.sort_values('total_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demonstration of Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Find similar Digimon\n",
    "test_digimon = \"Agumon\"\n",
    "print(f\"=== RECOMMENDATIONS FOR {test_digimon} ===\")\n",
    "\n",
    "# Overall similarity\n",
    "print(\"\\n1. Overall Similarity (all features):\")\n",
    "overall_recs = recommend_similar_digimon(test_digimon, cosine_sim_df, top_k=10)\n",
    "if isinstance(overall_recs, pd.DataFrame):\n",
    "    print(overall_recs)\n",
    "else:\n",
    "    print(overall_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move-based similarity\n",
    "print(\"\\n2. Move-based Similarity:\")\n",
    "move_recs = recommend_similar_digimon(test_digimon, jaccard_sim_df, top_k=10)\n",
    "if isinstance(move_recs, pd.DataFrame):\n",
    "    print(move_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type-Attribute similarity\n",
    "print(\"\\n3. Type-Attribute Similarity:\")\n",
    "type_attr_recs = recommend_similar_digimon(test_digimon, type_attr_sim_df, top_k=10)\n",
    "if isinstance(type_attr_recs, pd.DataFrame):\n",
    "    print(type_attr_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Evolution path recommendations\n",
    "print(f\"\\n=== EVOLUTION PATHS FOR {test_digimon} ===\")\n",
    "\n",
    "# Build directed evolution graph\n",
    "evolution_graph = nx.DiGraph()\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    evolution_graph.add_node(digimon['name_en'])\n",
    "for evo in evolution_data:\n",
    "    if evo['from_digimon'] in evolution_graph and evo['to_digimon'] in evolution_graph:\n",
    "        evolution_graph.add_edge(evo['from_digimon'], evo['to_digimon'])\n",
    "\n",
    "evolution_paths = recommend_evolution_path(test_digimon, evolution_graph, digimon_df)\n",
    "if isinstance(evolution_paths, pd.DataFrame):\n",
    "    print(evolution_paths)\n",
    "else:\n",
    "    print(evolution_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Team composition recommendations\n",
    "current_team = [\"Agumon\", \"Gabumon\", \"Patamon\"]\n",
    "print(f\"\\n=== TEAM COMPOSITION RECOMMENDATIONS ===\")\n",
    "print(f\"Current team: {', '.join(current_team)}\")\n",
    "\n",
    "team_recs = recommend_team_composition(current_team, digimon_df, cosine_sim_df)\n",
    "if isinstance(team_recs, pd.DataFrame):\n",
    "    print(\"\\nRecommended additions:\")\n",
    "    print(team_recs[['name', 'type', 'attribute', 'level', 'total_score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Similarity Analysis Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Cosine similarity distribution\n",
    "ax = axes[0, 0]\n",
    "cosine_values = cosine_sim_df.values[np.triu_indices_from(cosine_sim_df.values, k=1)]\n",
    "ax.hist(cosine_values, bins=50, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Cosine Similarity')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Overall Feature Similarity Distribution', fontweight='bold')\n",
    "ax.axvline(cosine_values.mean(), color='red', linestyle='--', \n",
    "          label=f'Mean: {cosine_values.mean():.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# Jaccard similarity distribution\n",
    "ax = axes[0, 1]\n",
    "jaccard_values = jaccard_sim_df.values[np.triu_indices_from(jaccard_sim_df.values, k=1)]\n",
    "ax.hist(jaccard_values, bins=50, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Jaccard Similarity')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Move-based Similarity Distribution', fontweight='bold')\n",
    "ax.axvline(jaccard_values.mean(), color='red', linestyle='--',\n",
    "          label=f'Mean: {jaccard_values.mean():.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# Type-Attribute similarity distribution\n",
    "ax = axes[1, 0]\n",
    "type_attr_values = type_attr_sim_df.values[np.triu_indices_from(type_attr_sim_df.values, k=1)]\n",
    "ax.hist(type_attr_values, bins=50, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Cosine Similarity')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Type-Attribute Similarity Distribution', fontweight='bold')\n",
    "ax.axvline(type_attr_values.mean(), color='red', linestyle='--',\n",
    "          label=f'Mean: {type_attr_values.mean():.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# Graph distance similarity distribution\n",
    "ax = axes[1, 1]\n",
    "graph_values = graph_sim_df.values[np.triu_indices_from(graph_sim_df.values, k=1)]\n",
    "graph_values_nonzero = graph_values[graph_values > 0]\n",
    "ax.hist(graph_values_nonzero, bins=50, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Graph Similarity')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Graph Distance Similarity Distribution (non-zero)', fontweight='bold')\n",
    "ax.axvline(graph_values_nonzero.mean(), color='red', linestyle='--',\n",
    "          label=f'Mean: {graph_values_nonzero.mean():.3f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"similarity_distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity heatmap for a sample of Digimon\n",
    "# Select diverse sample\n",
    "sample_indices = [\n",
    "    \"Agumon\", \"Gabumon\", \"Patamon\", \"Gatomon\", \"Veemon\",\n",
    "    \"MetalGreymon\", \"WereGarurumon\", \"Angemon\", \"Angewomon\",\n",
    "    \"Omnimon\", \"Alphamon\", \"Imperialdramon\", \"Gallantmon\",\n",
    "    \"Beelzemon\", \"Leomon\", \"Devimon\", \"Myotismon\", \"Piedmon\",\n",
    "    \"Machinedramon\", \"Puppetmon\"\n",
    "]\n",
    "\n",
    "# Filter to available Digimon\n",
    "available_sample = [d for d in sample_indices if d in cosine_sim_df.index]\n",
    "sample_sim = cosine_sim_df.loc[available_sample, available_sample]\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(sample_sim, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "            square=True, cbar_kws={'label': 'Cosine Similarity'}, ax=ax)\n",
    "ax.set_title('Digimon Similarity Matrix (Sample)', fontsize=16, fontweight='bold')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"similarity_heatmap_sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recommendation diversity\n",
    "# Compare different similarity metrics for the same Digimon\n",
    "test_digimon_list = [\"Agumon\", \"Gabumon\", \"Patamon\", \"Veemon\", \"Guilmon\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(test_digimon_list), figsize=(20, 4))\n",
    "\n",
    "for idx, test_digi in enumerate(test_digimon_list):\n",
    "    if test_digi not in cosine_sim_df.index:\n",
    "        continue\n",
    "        \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get top 5 recommendations from each method\n",
    "    cosine_top5 = cosine_sim_df.loc[test_digi].sort_values(ascending=False)[1:6].index.tolist()\n",
    "    jaccard_top5 = jaccard_sim_df.loc[test_digi].sort_values(ascending=False)[1:6].index.tolist()\n",
    "    type_attr_top5 = type_attr_sim_df.loc[test_digi].sort_values(ascending=False)[1:6].index.tolist()\n",
    "    \n",
    "    # Create Venn diagram data\n",
    "    all_recs = set(cosine_top5 + jaccard_top5 + type_attr_top5)\n",
    "    rec_matrix = []\n",
    "    \n",
    "    for rec in all_recs:\n",
    "        row = [\n",
    "            1 if rec in cosine_top5 else 0,\n",
    "            1 if rec in jaccard_top5 else 0,\n",
    "            1 if rec in type_attr_top5 else 0\n",
    "        ]\n",
    "        rec_matrix.append(row)\n",
    "    \n",
    "    rec_df = pd.DataFrame(rec_matrix, index=list(all_recs), \n",
    "                         columns=['Overall', 'Moves', 'Type/Attr'])\n",
    "    \n",
    "    # Plot\n",
    "    sns.heatmap(rec_df.T, cmap='Blues', cbar=False, \n",
    "               xticklabels=True, yticklabels=True, ax=ax)\n",
    "    ax.set_title(f'{test_digi} Top-5 Recs', fontsize=12)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "plt.suptitle('Recommendation Method Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"recommendation_method_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embedding-based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create low-dimensional embeddings using PCA\n",
    "print(\"=== CREATING DIGIMON EMBEDDINGS ===\")\n",
    "\n",
    "# Use PCA to create embeddings\n",
    "n_components = 50\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "embeddings = pca.fit_transform(feature_matrix_scaled)\n",
    "\n",
    "print(f\"Created {n_components}-dimensional embeddings\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Create embedding similarity matrix\n",
    "embedding_sim = cosine_similarity(embeddings)\n",
    "embedding_sim_df = pd.DataFrame(\n",
    "    embedding_sim,\n",
    "    index=feature_matrix.index,\n",
    "    columns=feature_matrix.index\n",
    ")\n",
    "\n",
    "# Test embedding-based recommendations\n",
    "print(f\"\\nEmbedding-based recommendations for {test_digimon}:\")\n",
    "embedding_recs = recommend_similar_digimon(test_digimon, embedding_sim_df, top_k=10)\n",
    "if isinstance(embedding_recs, pd.DataFrame):\n",
    "    print(embedding_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings in 2D\n",
    "# Further reduce to 2D for visualization\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca_2d.fit_transform(embeddings)\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Color by type\n",
    "type_colors = []\n",
    "for idx in feature_matrix.index:\n",
    "    digimon_type = features_df.loc[idx, 'type']\n",
    "    type_colors.append(TYPE_COLORS.get(digimon_type, '#808080'))\n",
    "\n",
    "scatter1 = ax1.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                      c=type_colors, alpha=0.6, s=50)\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.set_title('Digimon Embeddings Colored by Type', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Color by attribute\n",
    "attr_colors = []\n",
    "for idx in feature_matrix.index:\n",
    "    digimon_attr = features_df.loc[idx, 'attribute']\n",
    "    attr_colors.append(ATTRIBUTE_COLORS.get(digimon_attr, '#808080'))\n",
    "\n",
    "scatter2 = ax2.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                      c=attr_colors, alpha=0.6, s=50)\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC2')\n",
    "ax2.set_title('Digimon Embeddings Colored by Attribute', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add some labels for reference\n",
    "label_indices = [\"Agumon\", \"Gabumon\", \"Omnimon\", \"Alphamon\"]\n",
    "for label in label_indices:\n",
    "    if label in feature_matrix.index:\n",
    "        idx = feature_matrix.index.get_loc(label)\n",
    "        ax1.annotate(label, (embeddings_2d[idx, 0], embeddings_2d[idx, 1]), \n",
    "                    fontsize=8, alpha=0.7)\n",
    "        ax2.annotate(label, (embeddings_2d[idx, 0], embeddings_2d[idx, 1]), \n",
    "                    fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"digimon_embeddings_2d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommendation API functions\n",
    "class DigimonRecommender:\n",
    "    def __init__(self, similarity_matrices, digimon_data, evolution_graph):\n",
    "        self.similarity_matrices = similarity_matrices\n",
    "        self.digimon_data = digimon_data\n",
    "        self.evolution_graph = evolution_graph\n",
    "    \n",
    "    def get_similar(self, digimon_name, method='overall', top_k=10):\n",
    "        \"\"\"Get similar Digimon using specified method.\"\"\"\n",
    "        if method == 'overall':\n",
    "            sim_matrix = self.similarity_matrices['cosine']\n",
    "        elif method == 'moves':\n",
    "            sim_matrix = self.similarity_matrices['jaccard']\n",
    "        elif method == 'type_attribute':\n",
    "            sim_matrix = self.similarity_matrices['type_attr']\n",
    "        elif method == 'embedding':\n",
    "            sim_matrix = self.similarity_matrices['embedding']\n",
    "        else:\n",
    "            return \"Invalid method. Choose from: overall, moves, type_attribute, embedding\"\n",
    "        \n",
    "        return recommend_similar_digimon(digimon_name, sim_matrix, top_k)\n",
    "    \n",
    "    def get_evolution_paths(self, digimon_name, max_paths=10):\n",
    "        \"\"\"Get recommended evolution paths.\"\"\"\n",
    "        paths = recommend_evolution_path(digimon_name, self.evolution_graph, self.digimon_data)\n",
    "        if isinstance(paths, pd.DataFrame):\n",
    "            return paths.head(max_paths)\n",
    "        return paths\n",
    "    \n",
    "    def build_team(self, current_team, team_size=6):\n",
    "        \"\"\"Recommend Digimon to complete a team.\"\"\"\n",
    "        recommendations = recommend_team_composition(\n",
    "            current_team, \n",
    "            self.digimon_data, \n",
    "            self.similarity_matrices['cosine']\n",
    "        )\n",
    "        \n",
    "        if isinstance(recommendations, pd.DataFrame):\n",
    "            needed = team_size - len(current_team)\n",
    "            return recommendations.head(needed)\n",
    "        return recommendations\n",
    "\n",
    "# Initialize recommender\n",
    "recommender = DigimonRecommender(\n",
    "    similarity_matrices={\n",
    "        'cosine': cosine_sim_df,\n",
    "        'jaccard': jaccard_sim_df,\n",
    "        'type_attr': type_attr_sim_df,\n",
    "        'embedding': embedding_sim_df\n",
    "    },\n",
    "    digimon_data=digimon_df,\n",
    "    evolution_graph=evolution_graph\n",
    ")\n",
    "\n",
    "print(\"Recommendation system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save recommendation system components\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "results_dir = Path('../results/data')\n",
    "models_dir = Path('../results/models')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save similarity matrices (sample for size)\n",
    "print(\"Saving recommendation system components...\")\n",
    "\n",
    "# Save a sample of similarity matrices\n",
    "sample_size = min(500, len(cosine_sim_df))\n",
    "sample_indices = cosine_sim_df.index[:sample_size]\n",
    "\n",
    "similarity_samples = {\n",
    "    'cosine': cosine_sim_df.loc[sample_indices, sample_indices],\n",
    "    'jaccard': jaccard_sim_df.loc[sample_indices, sample_indices],\n",
    "    'type_attr': type_attr_sim_df.loc[sample_indices, sample_indices]\n",
    "}\n",
    "\n",
    "with open(models_dir / 'similarity_matrices_sample.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_samples, f)\n",
    "\n",
    "# Save embeddings\n",
    "embedding_data = {\n",
    "    'embeddings': embeddings,\n",
    "    'embeddings_2d': embeddings_2d,\n",
    "    'index': feature_matrix.index.tolist(),\n",
    "    'pca_model': pca,\n",
    "    'pca_2d_model': pca_2d\n",
    "}\n",
    "\n",
    "with open(models_dir / 'digimon_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_data, f)\n",
    "\n",
    "# Save recommendation examples\n",
    "test_examples = [\n",
    "    \"Agumon\", \"Gabumon\", \"Patamon\", \"Veemon\", \"Guilmon\",\n",
    "    \"Renamon\", \"Impmon\", \"Terriermon\", \"Lopmon\", \"Falcomon\"\n",
    "]\n",
    "\n",
    "recommendation_examples = {}\n",
    "for test_digi in test_examples:\n",
    "    if test_digi in cosine_sim_df.index:\n",
    "        recommendation_examples[test_digi] = {\n",
    "            'overall': recommender.get_similar(test_digi, 'overall', 5).to_dict('records') \n",
    "                      if isinstance(recommender.get_similar(test_digi, 'overall', 5), pd.DataFrame) else [],\n",
    "            'moves': recommender.get_similar(test_digi, 'moves', 5).to_dict('records')\n",
    "                    if isinstance(recommender.get_similar(test_digi, 'moves', 5), pd.DataFrame) else [],\n",
    "            'type_attribute': recommender.get_similar(test_digi, 'type_attribute', 5).to_dict('records')\n",
    "                            if isinstance(recommender.get_similar(test_digi, 'type_attribute', 5), pd.DataFrame) else []\n",
    "        }\n",
    "\n",
    "with open(results_dir / 'recommendation_examples.json', 'w') as f:\n",
    "    json.dump(recommendation_examples, f, indent=2)\n",
    "\n",
    "# Save summary statistics\n",
    "recommendation_stats = {\n",
    "    'total_digimon': len(digimon_df),\n",
    "    'features_used': len(numeric_features),\n",
    "    'embedding_dimensions': n_components,\n",
    "    'explained_variance': float(pca.explained_variance_ratio_.sum()),\n",
    "    'similarity_metrics': ['cosine', 'jaccard', 'type_attribute', 'embedding'],\n",
    "    'average_similarities': {\n",
    "        'cosine': float(cosine_values.mean()),\n",
    "        'jaccard': float(jaccard_values.mean()),\n",
    "        'type_attribute': float(type_attr_values.mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(results_dir / 'recommendation_system_stats.json', 'w') as f:\n",
    "    json.dump(recommendation_stats, f, indent=2)\n",
    "\n",
    "print(\"Recommendation system components saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Recommendation System Insights:\n",
    "\n",
    "1. **Similarity Metrics**:\n",
    "   - Different similarity metrics capture different aspects of Digimon relationships\n",
    "   - Overall feature similarity provides balanced recommendations\n",
    "   - Move-based similarity identifies combat-style similarities\n",
    "   - Type-attribute similarity finds categorically similar Digimon\n",
    "\n",
    "2. **Recommendation Quality**:\n",
    "   - High similarity scores indicate strong relationships\n",
    "   - Multiple metrics provide diverse recommendation options\n",
    "   - Evolution paths follow logical progression patterns\n",
    "\n",
    "3. **Team Composition**:\n",
    "   - Balancing diversity and synergy creates optimal teams\n",
    "   - Type coverage important for strategic advantage\n",
    "   - Attribute balance provides tactical flexibility\n",
    "\n",
    "4. **Embedding Insights**:\n",
    "   - Low-dimensional embeddings preserve meaningful structure\n",
    "   - Clear clustering by type and attribute in embedding space\n",
    "   - Embeddings enable fast similarity computations\n",
    "\n",
    "### Applications:\n",
    "- **Game Design**: Suggest evolution paths and team compositions\n",
    "- **Content Discovery**: Help players find similar Digimon\n",
    "- **Strategic Planning**: Build balanced teams for battles\n",
    "- **Collection Guidance**: Recommend next Digimon to pursue\n",
    "\n",
    "The recommendation system successfully leverages the knowledge graph structure to provide meaningful suggestions across multiple use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Recommendation system analysis complete! Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}