{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 06: Centrality & Influence Analysis\n",
    "\n",
    "**Objective**: Identify the most important and influential Digimon in the knowledge graph.\n",
    "\n",
    "This notebook explores:\n",
    "- Various centrality measures (degree, betweenness, closeness, eigenvector, PageRank)\n",
    "- Custom influence metrics\n",
    "- Comparative analysis of centrality measures\n",
    "- Visualization of influential nodes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:31.204739Z",
     "start_time": "2025-08-12T01:50:30.385183Z"
    }
   },
   "source": "# Standard imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\nfrom collections import defaultdict\nfrom scipy.stats import pearsonr, spearmanr\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Custom utilities\nfrom utils import (\n    Neo4jConnector,\n    calculate_centrality_measures,\n    plot_centrality_comparison,\n    plot_network_static,\n    save_figure,\n    TYPE_COLORS, LEVEL_COLORS, ATTRIBUTE_COLORS\n)\n\n# Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\npd.set_option('display.precision', 3)\n\n# Notebook configuration\nnotebook_name = \"06_centrality_analysis\"\n\nprint(\"Environment setup complete!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Network Graphs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:32.556885Z",
     "start_time": "2025-08-12T01:50:32.341369Z"
    }
   },
   "source": "# Connect to database\nconn = Neo4jConnector()\nprint(\"Connected to Neo4j database\")\n\n# Get all data\ndigimon_df = conn.get_all_digimon()\nevolution_data = conn.get_evolution_chains()\nmoves_df = conn.get_digimon_moves()\n\n# Remove any rows with missing name_en\ndigimon_df = digimon_df.dropna(subset=['name_en'])\n\nprint(f\"\\nLoaded data:\")\nprint(f\"  - {len(digimon_df)} Digimon (with valid names)\")\nprint(f\"  - {len(evolution_data)} evolution relationships\")\nprint(f\"  - {len(moves_df)} move relationships\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j database\n",
      "\n",
      "Loaded data:\n",
      "  - 1249 Digimon (with valid names)\n",
      "  - 3746 evolution relationships\n",
      "  - 2433 move relationships\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:33.168900Z",
     "start_time": "2025-08-12T01:50:33.080813Z"
    }
   },
   "source": "# Build multiple network representations\n\n# 1. Evolution Network (Directed)\nevolution_graph = nx.DiGraph()\nfor _, digimon in digimon_df.iterrows():\n    if digimon['name_en'] is not None:  # Safety check\n        evolution_graph.add_node(\n            digimon['name_en'],\n            level=digimon['level'],\n            type=digimon['type'],\n            attribute=digimon['attribute']\n        )\n\nfor evo in evolution_data:\n    if evo['from_digimon'] in evolution_graph and evo['to_digimon'] in evolution_graph:\n        evolution_graph.add_edge(evo['from_digimon'], evo['to_digimon'])\n\nprint(f\"Evolution network: {evolution_graph.number_of_nodes()} nodes, {evolution_graph.number_of_edges()} edges\")\n\n# 2. Similarity Network (Undirected) - based on shared attributes\nsimilarity_graph = nx.Graph()\nfor _, digimon in digimon_df.iterrows():\n    if digimon['name_en'] is not None:  # Safety check\n        similarity_graph.add_node(\n            digimon['name_en'],\n            level=digimon['level'],\n            type=digimon['type'],\n            attribute=digimon['attribute']\n        )\n\n# Add edges for shared types (sample for efficiency)\ntype_groups = digimon_df.groupby('type')['name_en'].apply(list)\nfor type_name, digimon_list in type_groups.items():\n    if 2 <= len(digimon_list) <= 30:  # Reasonable group sizes\n        for i in range(len(digimon_list)):\n            for j in range(i + 1, min(i + 5, len(digimon_list))):\n                similarity_graph.add_edge(digimon_list[i], digimon_list[j], weight=1.0)\n\n# Add edges for shared moves\nmove_groups = moves_df.groupby('move')['digimon'].apply(list)\nfor move, digimon_list in move_groups.items():\n    if 2 <= len(digimon_list) <= 10:  # Rare moves only\n        for i in range(len(digimon_list)):\n            for j in range(i + 1, len(digimon_list)):\n                if digimon_list[i] in similarity_graph and digimon_list[j] in similarity_graph:\n                    if similarity_graph.has_edge(digimon_list[i], digimon_list[j]):\n                        similarity_graph[digimon_list[i]][digimon_list[j]]['weight'] += 0.5\n                    else:\n                        similarity_graph.add_edge(digimon_list[i], digimon_list[j], weight=0.5)\n\nprint(f\"Similarity network: {similarity_graph.number_of_nodes()} nodes, {similarity_graph.number_of_edges()} edges\")\n\n# 3. Combined Network (for comprehensive analysis)\ncombined_graph = nx.Graph()\n# Add all nodes\nfor node, attrs in evolution_graph.nodes(data=True):\n    combined_graph.add_node(node, **attrs)\n# Add evolution edges\nfor u, v in evolution_graph.edges():\n    combined_graph.add_edge(u, v, weight=2.0, type='evolution')\n# Add similarity edges\nfor u, v, data in similarity_graph.edges(data=True):\n    if combined_graph.has_edge(u, v):\n        combined_graph[u][v]['weight'] += data['weight']\n    else:\n        combined_graph.add_edge(u, v, weight=data['weight'], type='similarity')\n\nprint(f\"Combined network: {combined_graph.number_of_nodes()} nodes, {combined_graph.number_of_edges()} edges\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolution network: 1249 nodes, 3713 edges\n",
      "Similarity network: 1249 nodes, 2034 edges\n",
      "Combined network: 1249 nodes, 4916 edges\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:36.588168Z",
     "start_time": "2025-08-12T01:50:34.949556Z"
    }
   },
   "source": [
    "# Calculate centrality for evolution network\n",
    "print(\"=== EVOLUTION NETWORK CENTRALITY ===\")\n",
    "evolution_centrality = calculate_centrality_measures(evolution_graph)\n",
    "evolution_centrality = evolution_centrality.sort_values('degree', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 by degree centrality (most evolution connections):\")\n",
    "for idx, row in evolution_centrality.head(10).iterrows():\n",
    "    in_deg = evolution_graph.in_degree(idx) if idx in evolution_graph else 0\n",
    "    out_deg = evolution_graph.out_degree(idx) if idx in evolution_graph else 0\n",
    "    print(f\"  {idx}: in={in_deg}, out={out_deg}, total={in_deg+out_deg}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVOLUTION NETWORK CENTRALITY ===\n",
      "\n",
      "Top 10 by degree centrality (most evolution connections):\n",
      "  TAILMON: in=18, out=3, total=21\n",
      "  MUGENDRAMON: in=15, out=3, total=18\n",
      "  SHOUTMON: in=13, out=3, total=16\n",
      "  WEZENGAMMAMON: in=13, out=3, total=16\n",
      "  LUCEMON_X: in=12, out=3, total=15\n",
      "  GANKOOMON_X: in=12, out=3, total=15\n",
      "  JESMONGX: in=12, out=3, total=15\n",
      "  HAWKMON: in=11, out=3, total=14\n",
      "  MARINANGEMON: in=11, out=3, total=14\n",
      "  CRANIUMMON_X: in=11, out=3, total=14\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:37.525166Z",
     "start_time": "2025-08-12T01:50:36.597127Z"
    }
   },
   "source": [
    "# Calculate centrality for similarity network\n",
    "print(\"\\n=== SIMILARITY NETWORK CENTRALITY ===\")\n",
    "similarity_centrality = calculate_centrality_measures(similarity_graph)\n",
    "similarity_centrality = similarity_centrality.sort_values('degree', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 by degree centrality (most similar Digimon):\")\n",
    "for idx, row in similarity_centrality.head(10).iterrows():\n",
    "    degree = similarity_graph.degree(idx)\n",
    "    node_data = similarity_graph.nodes[idx]\n",
    "    print(f\"  {idx} ({node_data['type']}/{node_data['attribute']}): {degree} connections\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SIMILARITY NETWORK CENTRALITY ===\n",
      "\n",
      "Top 10 by degree centrality (most similar Digimon):\n",
      "  NUMEMON (Fluffy body Type/Virus): 11 connections\n",
      "  KOROMON (Lesser Type/): 10 connections\n",
      "  PILLOMON (mammalian Type/Vaccine): 10 connections\n",
      "  CERBERUMON_X (Demon Beast Type/Vaccine): 10 connections\n",
      "  BEELZEBUMON:BLASTMODE (Demon King Type/Virus): 10 connections\n",
      "  CERBERUMON (Demon Beast Type/Vaccine): 10 connections\n",
      "  PAGUMON (Lesser Type/): 10 connections\n",
      "  HUCKMON (Little Dragon Type/Data): 10 connections\n",
      "  GEOGREYMON (dinosaur Type/Vaccine): 9 connections\n",
      "  SKULLSEADRAMON (Undead Type/Virus): 9 connections\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:41.179974Z",
     "start_time": "2025-08-12T01:50:37.540336Z"
    }
   },
   "source": [
    "# Calculate centrality for combined network\n",
    "print(\"\\n=== COMBINED NETWORK CENTRALITY ===\")\n",
    "combined_centrality = calculate_centrality_measures(combined_graph)\n",
    "\n",
    "# Add node attributes to centrality DataFrame\n",
    "for node in combined_centrality.index:\n",
    "    if node in combined_graph:\n",
    "        attrs = combined_graph.nodes[node]\n",
    "        combined_centrality.loc[node, 'type'] = attrs.get('type', 'Unknown')\n",
    "        combined_centrality.loc[node, 'level'] = attrs.get('level', 'Unknown')\n",
    "        combined_centrality.loc[node, 'attribute'] = attrs.get('attribute', 'Unknown')\n",
    "\n",
    "print(\"\\nCentrality measures calculated for all networks\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMBINED NETWORK CENTRALITY ===\n",
      "\n",
      "Centrality measures calculated for all networks\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Influence Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:42.199885Z",
     "start_time": "2025-08-12T01:50:41.193370Z"
    }
   },
   "source": [
    "# Calculate custom influence scores\n",
    "influence_scores = pd.DataFrame(index=combined_centrality.index)\n",
    "\n",
    "# 1. Evolution Influence Score\n",
    "# Higher score for Digimon that are central in evolution chains\n",
    "for node in influence_scores.index:\n",
    "    if node in evolution_graph:\n",
    "        ancestors = len(nx.ancestors(evolution_graph, node))\n",
    "        descendants = len(nx.descendants(evolution_graph, node))\n",
    "        evolution_influence = (ancestors + descendants * 2) / evolution_graph.number_of_nodes()\n",
    "    else:\n",
    "        evolution_influence = 0\n",
    "    influence_scores.loc[node, 'evolution_influence'] = evolution_influence\n",
    "\n",
    "# 2. Type Diversity Index\n",
    "# Score based on connections to different types\n",
    "for node in influence_scores.index:\n",
    "    if node in combined_graph:\n",
    "        neighbor_types = set()\n",
    "        for neighbor in combined_graph.neighbors(node):\n",
    "            neighbor_type = combined_graph.nodes[neighbor].get('type', 'Unknown')\n",
    "            neighbor_types.add(neighbor_type)\n",
    "        type_diversity = len(neighbor_types) / digimon_df['type'].nunique()\n",
    "    else:\n",
    "        type_diversity = 0\n",
    "    influence_scores.loc[node, 'type_diversity'] = type_diversity\n",
    "\n",
    "# 3. Move Uniqueness Score\n",
    "# Higher score for Digimon with rare moves\n",
    "move_counts = moves_df['move'].value_counts()\n",
    "for node in influence_scores.index:\n",
    "    node_moves = moves_df[moves_df['digimon'] == node]['move'].tolist()\n",
    "    if node_moves:\n",
    "        # Calculate average rarity of moves (inverse of frequency)\n",
    "        move_rarities = [1 / move_counts[move] for move in node_moves]\n",
    "        move_uniqueness = np.mean(move_rarities) * 100\n",
    "    else:\n",
    "        move_uniqueness = 0\n",
    "    influence_scores.loc[node, 'move_uniqueness'] = move_uniqueness\n",
    "\n",
    "# 4. Combined Influence Score\n",
    "# Weighted combination of all metrics\n",
    "influence_scores['combined_influence'] = (\n",
    "    combined_centrality['degree'] * 0.2 +\n",
    "    combined_centrality['betweenness'] * 0.2 +\n",
    "    combined_centrality['eigenvector'] * 0.2 +\n",
    "    combined_centrality['pagerank'] * 100 * 0.2 +\n",
    "    influence_scores['evolution_influence'] * 0.1 +\n",
    "    influence_scores['type_diversity'] * 0.05 +\n",
    "    influence_scores['move_uniqueness'] * 0.05\n",
    ")\n",
    "\n",
    "# Normalize to 0-1 scale\n",
    "for col in influence_scores.columns:\n",
    "    if influence_scores[col].max() > 0:\n",
    "        influence_scores[col] = influence_scores[col] / influence_scores[col].max()\n",
    "\n",
    "print(\"Custom influence metrics calculated\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom influence metrics calculated\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:42.222106Z",
     "start_time": "2025-08-12T01:50:42.216593Z"
    }
   },
   "source": [
    "# Combine all metrics\n",
    "all_metrics = pd.concat([combined_centrality, influence_scores], axis=1)\n",
    "all_metrics = all_metrics.sort_values('combined_influence', ascending=False)\n",
    "\n",
    "print(\"=== TOP 20 MOST INFLUENTIAL DIGIMON ===\")\n",
    "print(\"\\nRank | Digimon | Type | Level | Combined Score\")\n",
    "print(\"-\" * 60)\n",
    "for i, (idx, row) in enumerate(all_metrics.head(20).iterrows()):\n",
    "    print(f\"{i+1:4d} | {idx:20s} | {row['type']:15s} | {row['level']:10s} | {row['combined_influence']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 20 MOST INFLUENTIAL DIGIMON ===\n",
      "\n",
      "Rank | Digimon | Type | Level | Combined Score\n",
      "------------------------------------------------------------\n",
      "   1 | MARINANGEMON         | fairy Type      | Mega       | 1.000\n",
      "   2 | SKULLKNIGHTMON       | Undead Type     | Maturity (Cross Wars) | 0.998\n",
      "   3 | HAWKMON              | bird Type       | Rookie     | 0.998\n",
      "   4 | RAREMON              | Undead Type     | Champion   | 0.997\n",
      "   5 | ARMADIMON            | mammalian Type  | Rookie     | 0.997\n",
      "   6 | V-MON                | Little Dragon Type | Rookie     | 0.996\n",
      "   7 | MUGENDRAMON          | Machine Type    | Mega       | 0.996\n",
      "   8 | MAQUINAMON           | Synthesis Type  | Rookie     | 0.996\n",
      "   9 | WORMMON              | Larva Type      | Rookie     | 0.996\n",
      "  10 | LOTUSMON             | fairy Type      | Mega       | 0.996\n",
      "  11 | DINOMON              | dinosaur Type   | Mega       | 0.996\n",
      "  12 | MARINDEVIMON         | Aquatic Beast Man Type | Ultimate   | 0.996\n",
      "  13 | DIMETROMON           | reptiles Type   | Champion   | 0.996\n",
      "  14 | KANGARUMON           | mammalian Type  | Armor      | 0.995\n",
      "  15 | LILAMON              | fairy Type      | Ultimate   | 0.995\n",
      "  16 | ELIZAMON             | reptiles Type   | Rookie     | 0.995\n",
      "  17 | OCTMON               | Fluffy body Type | Champion   | 0.995\n",
      "  18 | LALAMON              | plant Type      | Rookie     | 0.995\n",
      "  19 | LAMIAMON             | Dragon Type     | Ultimate   | 0.995\n",
      "  20 | LUNAMON              | mammalian Type  | Rookie     | 0.995\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:43.167412Z",
     "start_time": "2025-08-12T01:50:42.230314Z"
    }
   },
   "source": "# Correlation between centrality measures\ncentrality_cols = ['degree', 'betweenness', 'closeness', 'eigenvector', 'pagerank']\ncorrelation_matrix = combined_centrality[centrality_cols].corr(method='spearman')\n\nprint(\"=== CENTRALITY MEASURE CORRELATIONS ===\")\nprint(correlation_matrix.round(3))\n\n# Visualize correlation matrix\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n            center=0, square=True, ax=ax)\nax.set_title('Centrality Measure Correlations (Spearman)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nsave_figure(fig, \"centrality_correlations\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:43.902211Z",
     "start_time": "2025-08-12T01:50:43.191198Z"
    }
   },
   "source": "# Ranking stability analysis\n# Compare top-k rankings across different measures\nk = 50\nranking_overlap = pd.DataFrame(index=centrality_cols, columns=centrality_cols)\n\nfor measure1 in centrality_cols:\n    top_k1 = set(combined_centrality.nlargest(k, measure1).index)\n    for measure2 in centrality_cols:\n        top_k2 = set(combined_centrality.nlargest(k, measure2).index)\n        overlap = len(top_k1 & top_k2) / k\n        ranking_overlap.loc[measure1, measure2] = overlap\n\n# Convert to numeric\nranking_overlap = ranking_overlap.astype(float)\n\nprint(f\"\\n=== TOP-{k} RANKING OVERLAP ===\")\nprint(ranking_overlap.round(2))\n\n# Visualize\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(ranking_overlap, annot=True, fmt='.2f', cmap='YlOrRd', \n            vmin=0, vmax=1, square=True, ax=ax)\nax.set_title(f'Top-{k} Ranking Overlap Between Measures', fontsize=14, fontweight='bold')\nplt.tight_layout()\nsave_figure(fig, \"ranking_overlap\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:44.756697Z",
     "start_time": "2025-08-12T01:50:43.908185Z"
    }
   },
   "source": "# Centrality by level analysis\nlevel_centrality = all_metrics.groupby('level')[centrality_cols].mean()\nlevel_order = ['Baby', 'In-Training', 'Rookie', 'Champion', 'Ultimate', 'Mega', 'Ultra']\nlevel_centrality = level_centrality.reindex(level_order, fill_value=0)\n\nprint(\"\\n=== AVERAGE CENTRALITY BY LEVEL ===\")\nprint(level_centrality.round(3))\n\n# Visualize\nfig, ax = plt.subplots(figsize=(10, 6))\nlevel_centrality.plot(kind='bar', ax=ax, colormap='viridis')\nax.set_xlabel('Level')\nax.set_ylabel('Average Centrality Score')\nax.set_title('Centrality Measures by Evolution Level', fontsize=16, fontweight='bold')\nax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xticks(rotation=45)\nplt.tight_layout()\nsave_figure(fig, \"centrality_by_level\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:50:48.642451Z",
     "start_time": "2025-08-12T01:50:44.776612Z"
    }
   },
   "source": "# Top influential Digimon radar chart\ntop_n = 10\ntop_digimon = all_metrics.head(top_n)\n\n# Prepare data for radar chart\nmetrics_for_radar = ['degree', 'betweenness', 'eigenvector', 'pagerank', \n                    'evolution_influence', 'type_diversity']\n\nfig = make_subplots(\n    rows=2, cols=5,\n    subplot_titles=[name for name in top_digimon.index[:10]],\n    specs=[[{'type': 'polar'}] * 5] * 2\n)\n\nfor idx, (digimon_name, scores) in enumerate(top_digimon.iterrows()):\n    if idx >= 10:\n        break\n    \n    row = idx // 5 + 1\n    col = idx % 5 + 1\n    \n    values = [scores[metric] for metric in metrics_for_radar]\n    values.append(values[0])  # Close the polygon\n    \n    fig.add_trace(\n        go.Scatterpolar(\n            r=values,\n            theta=metrics_for_radar + [metrics_for_radar[0]],\n            fill='toself',\n            name=digimon_name\n        ),\n        row=row, col=col\n    )\n\nfig.update_layout(\n    showlegend=False,\n    title_text=\"Top 10 Influential Digimon - Centrality Profiles\",\n    height=800\n)\n\nsave_figure(fig, \"top_digimon_radar_charts\", notebook_name=notebook_name)\nfig.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:51:43.212412Z",
     "start_time": "2025-08-12T01:51:39.317750Z"
    }
   },
   "source": "# Centrality distribution plots\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.ravel()\n\nfor i, measure in enumerate(centrality_cols + ['combined_influence']):\n    ax = axes[i]\n    data = all_metrics[measure].dropna()\n    \n    # Plot histogram\n    ax.hist(data, bins=50, alpha=0.7, edgecolor='black')\n    ax.set_xlabel(measure.replace('_', ' ').title())\n    ax.set_ylabel('Count')\n    ax.set_title(f'{measure.replace(\"_\", \" \").title()} Distribution', fontweight='bold')\n    \n    # Add statistics\n    ax.axvline(data.mean(), color='red', linestyle='--', label=f'Mean: {data.mean():.3f}')\n    ax.axvline(data.median(), color='green', linestyle='--', label=f'Median: {data.median():.3f}')\n    ax.legend()\n    \n    # Log scale for better visualization\n    if measure in ['betweenness', 'degree']:\n        ax.set_yscale('log')\n\nplt.tight_layout()\nsave_figure(fig, \"centrality_distributions\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:52:04.078179Z",
     "start_time": "2025-08-12T01:52:00.863982Z"
    }
   },
   "source": "# Network visualization with node size by centrality\n# Create subgraph of most central nodes\ntop_nodes = all_metrics.head(100).index.tolist()\ncentral_subgraph = combined_graph.subgraph(top_nodes).copy()\n\n# Set node sizes based on combined influence\nnode_sizes = []\nnode_colors = []\nfor node in central_subgraph.nodes():\n    size = all_metrics.loc[node, 'combined_influence'] * 1000 + 100\n    node_sizes.append(size)\n    \n    # Color by level\n    level = central_subgraph.nodes[node].get('level', 'Unknown')\n    color = LEVEL_COLORS.get(level, '#808080')\n    node_colors.append(color)\n\n# Create visualization\nfig, ax = plt.subplots(figsize=(15, 15))\npos = nx.spring_layout(central_subgraph, k=3, iterations=50)\n\n# Draw network\nnx.draw_networkx_nodes(central_subgraph, pos, node_size=node_sizes, \n                      node_color=node_colors, alpha=0.8, ax=ax)\nnx.draw_networkx_edges(central_subgraph, pos, alpha=0.2, ax=ax)\n\n# Add labels for top nodes\ntop_20 = all_metrics.head(20).index\nlabels = {node: node for node in top_20 if node in central_subgraph}\nnx.draw_networkx_labels(central_subgraph, pos, labels, font_size=8, ax=ax)\n\nax.set_title('Network of Most Influential Digimon\\n(Node size = influence, Color = level)', \n            fontsize=20, fontweight='bold', pad=20)\nax.axis('off')\n\n# Add legend for levels\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor=color, label=level) \n                  for level, color in LEVEL_COLORS.items()]\nax.legend(handles=legend_elements, loc='upper right', title='Level')\n\nplt.tight_layout()\nsave_figure(fig, \"influential_digimon_network\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:52:24.518799Z",
     "start_time": "2025-08-12T01:52:22.952078Z"
    }
   },
   "source": "# Influence by type analysis\ntype_influence = all_metrics.groupby('type')['combined_influence'].agg(['mean', 'max', 'count'])\ntype_influence = type_influence[type_influence['count'] >= 5]  # Types with at least 5 Digimon\ntype_influence = type_influence.sort_values('mean', ascending=False).head(20)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\n# Average influence by type\ncolors = [TYPE_COLORS.get(t, '#808080') for t in type_influence.index]\nbars1 = ax1.barh(range(len(type_influence)), type_influence['mean'], color=colors)\nax1.set_yticks(range(len(type_influence)))\nax1.set_yticklabels(type_influence.index)\nax1.set_xlabel('Average Combined Influence')\nax1.set_title('Average Influence by Type (Top 20)', fontsize=14, fontweight='bold')\nax1.invert_yaxis()\n\n# Add value labels\nfor i, bar in enumerate(bars1):\n    width = bar.get_width()\n    ax1.text(width, bar.get_y() + bar.get_height()/2, \n             f'{width:.3f}', ha='left', va='center', fontsize=8)\n\n# Max influence by type\nbars2 = ax2.barh(range(len(type_influence)), type_influence['max'], color=colors)\nax2.set_yticks(range(len(type_influence)))\nax2.set_yticklabels(type_influence.index)\nax2.set_xlabel('Maximum Combined Influence')\nax2.set_title('Maximum Influence by Type (Top 20)', fontsize=14, fontweight='bold')\nax2.invert_yaxis()\n\n# Add value labels\nfor i, bar in enumerate(bars2):\n    width = bar.get_width()\n    ax2.text(width, bar.get_y() + bar.get_height()/2, \n             f'{width:.3f}', ha='left', va='center', fontsize=8)\n\nplt.tight_layout()\nsave_figure(fig, \"influence_by_type\", notebook_name=notebook_name)\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:52:28.778690Z",
     "start_time": "2025-08-12T01:52:28.737417Z"
    }
   },
   "source": [
    "# HITS analysis (Hubs and Authorities) for evolution network\n",
    "hits_h, hits_a = nx.hits(evolution_graph, max_iter=100)\n",
    "\n",
    "# Convert to DataFrames\n",
    "hubs_df = pd.DataFrame.from_dict(hits_h, orient='index', columns=['hub_score'])\n",
    "authorities_df = pd.DataFrame.from_dict(hits_a, orient='index', columns=['authority_score'])\n",
    "hits_df = pd.concat([hubs_df, authorities_df], axis=1)\n",
    "hits_df = hits_df.sort_values('hub_score', ascending=False)\n",
    "\n",
    "print(\"=== EVOLUTION NETWORK HUBS AND AUTHORITIES ===\")\n",
    "print(\"\\nTop 10 Hubs (evolve into many):\")\n",
    "for idx, score in hits_df.head(10)['hub_score'].items():\n",
    "    out_deg = evolution_graph.out_degree(idx)\n",
    "    print(f\"  {idx}: hub_score={score:.3f}, out_degree={out_deg}\")\n",
    "\n",
    "print(\"\\nTop 10 Authorities (evolved from many):\")\n",
    "hits_df_auth = hits_df.sort_values('authority_score', ascending=False)\n",
    "for idx, score in hits_df_auth.head(10)['authority_score'].items():\n",
    "    in_deg = evolution_graph.in_degree(idx)\n",
    "    print(f\"  {idx}: authority_score={score:.3f}, in_degree={in_deg}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVOLUTION NETWORK HUBS AND AUTHORITIES ===\n",
      "\n",
      "Top 10 Hubs (evolve into many):\n",
      "  DUFTMON_X: hub_score=0.037, out_degree=3\n",
      "  DYNASMON_X: hub_score=0.036, out_degree=3\n",
      "  JESMONGX: hub_score=0.036, out_degree=3\n",
      "  EXAMON_X: hub_score=0.032, out_degree=3\n",
      "  SLEIPMON_X: hub_score=0.030, out_degree=3\n",
      "  ULFORCEVDRAMON_X: hub_score=0.027, out_degree=3\n",
      "  CRANIUMMON: hub_score=0.027, out_degree=3\n",
      "  MONZAEMON_X: hub_score=0.027, out_degree=3\n",
      "  SIESAMON_X: hub_score=0.026, out_degree=3\n",
      "  CHERUBIMON_X: hub_score=0.026, out_degree=3\n",
      "\n",
      "Top 10 Authorities (evolved from many):\n",
      "  GANKOOMON_X: authority_score=0.108, in_degree=12\n",
      "  CRANIUMMON_X: authority_score=0.097, in_degree=11\n",
      "  JESMONGX: authority_score=0.081, in_degree=12\n",
      "  EXAMON_X: authority_score=0.069, in_degree=10\n",
      "  MAGNAMON_X: authority_score=0.039, in_degree=8\n",
      "  ULFORCEVDRAMON_X: authority_score=0.037, in_degree=7\n",
      "  LORDKNIGHTMON_X: authority_score=0.029, in_degree=6\n",
      "  DUFTMON_X: authority_score=0.024, in_degree=5\n",
      "  JUSTIMON_X: authority_score=0.020, in_degree=5\n",
      "  ALPHAMON: authority_score=0.020, in_degree=8\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:52:47.654014Z",
     "start_time": "2025-08-12T01:52:47.622529Z"
    }
   },
   "source": "# Prepare export data\nfrom pathlib import Path\nimport json\n\nresults_dir = Path(f'../results/{notebook_name}/data')\nresults_dir.mkdir(parents=True, exist_ok=True)\n\n# Export centrality scores\nall_metrics.to_csv(results_dir / 'centrality_scores.csv')\n\n# Export top influential Digimon\ntop_100_influential = all_metrics.head(100)[['type', 'level', 'attribute', 'combined_influence'] + centrality_cols]\ntop_100_influential.to_csv(results_dir / 'top_100_influential_digimon.csv')\n\n# Export HITS scores\nhits_df.to_csv(results_dir / 'evolution_hubs_authorities.csv')\n\n# Export summary statistics\ncentrality_summary = {\n    'total_analyzed': int(len(all_metrics)),\n    'networks_analyzed': {\n        'evolution': {'nodes': evolution_graph.number_of_nodes(), \n                     'edges': evolution_graph.number_of_edges()},\n        'similarity': {'nodes': similarity_graph.number_of_nodes(), \n                       'edges': similarity_graph.number_of_edges()},\n        'combined': {'nodes': combined_graph.number_of_nodes(), \n                    'edges': combined_graph.number_of_edges()}\n    },\n    'most_influential': {\n        'overall': all_metrics.index[0],\n        'by_degree': combined_centrality.idxmax()['degree'],\n        'by_betweenness': combined_centrality.idxmax()['betweenness'],\n        'by_eigenvector': combined_centrality.idxmax()['eigenvector'],\n        'by_pagerank': combined_centrality.idxmax()['pagerank']\n    },\n    'centrality_correlations': correlation_matrix.to_dict(),\n    'average_scores': {\n        metric: float(all_metrics[metric].mean()) \n        for metric in centrality_cols + ['combined_influence']\n    }\n}\n\nwith open(results_dir / 'centrality_summary.json', 'w') as f:\n    json.dump(centrality_summary, f, indent=2)\n\nprint(\"Centrality analysis results exported successfully!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Centrality & Influence Insights:\n",
    "\n",
    "1. **Influential Digimon**:\n",
    "   - Clear hierarchy of influence exists in the network\n",
    "   - Top influential Digimon often serve as evolution hubs\n",
    "   - Different centrality measures capture different aspects of importance\n",
    "\n",
    "2. **Centrality Patterns**:\n",
    "   - Strong correlation between degree and eigenvector centrality\n",
    "   - Betweenness identifies bridge Digimon between communities\n",
    "   - PageRank effectively identifies globally important nodes\n",
    "\n",
    "3. **Level and Type Effects**:\n",
    "   - Middle evolution levels (Champion, Ultimate) show highest average centrality\n",
    "   - Certain types naturally have higher influence due to popularity\n",
    "   - Evolution patterns create natural hierarchies\n",
    "\n",
    "4. **Network Roles**:\n",
    "   - Hubs: Digimon that evolve into many forms\n",
    "   - Authorities: Popular evolution targets\n",
    "   - Bridges: Connect different parts of the network\n",
    "\n",
    "These insights reveal the power structure and influence dynamics within the Digimon universe, with implications for game balance and narrative importance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T01:52:50.520210Z",
     "start_time": "2025-08-12T01:52:50.516013Z"
    }
   },
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Centrality & influence analysis complete! Database connection closed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centrality & influence analysis complete! Database connection closed.\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}