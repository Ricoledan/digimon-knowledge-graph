{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05: Community Detection & Graph Clustering\n",
    "\n",
    "**Objective**: Identify natural groupings and communities in the Digimon Knowledge Graph.\n",
    "\n",
    "This notebook explores:\n",
    "- Community detection using multiple algorithms\n",
    "- Graph embeddings and clustering\n",
    "- Community validation and analysis\n",
    "- Visualization of community structure\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Graph embedding libraries\n",
    "from node2vec import Node2Vec\n",
    "from karateclub import DeepWalk, HOPE, NetMF\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    Neo4jConnector,\n",
    "    plot_network_interactive, plot_network_static,\n",
    "    plot_community_network, save_figure,\n",
    "    detect_communities_louvain, detect_communities_label_propagation,\n",
    "    detect_communities_girvan_newman, calculate_modularity,\n",
    "    TYPE_COLORS, ATTRIBUTE_COLORS, LEVEL_COLORS\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Digimon Relationship Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = Neo4jConnector()\n",
    "print(\"Connected to Neo4j database\")\n",
    "\n",
    "# Get all Digimon data\n",
    "digimon_df = conn.get_all_digimon()\n",
    "print(f\"Loaded {len(digimon_df)} Digimon\")\n",
    "\n",
    "# Build comprehensive relationship graph\n",
    "G = nx.Graph()  # Undirected for community detection\n",
    "\n",
    "# Add nodes with attributes\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    G.add_node(\n",
    "        digimon['name_en'],\n",
    "        level=digimon['level'],\n",
    "        type=digimon['type'],\n",
    "        attribute=digimon['attribute']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add different types of relationships\n",
    "\n",
    "# 1. Evolution relationships\n",
    "evolution_data = conn.get_evolution_chains()\n",
    "for evo in evolution_data:\n",
    "    if evo['from_digimon'] in G and evo['to_digimon'] in G:\n",
    "        G.add_edge(evo['from_digimon'], evo['to_digimon'], \n",
    "                  weight=3.0, type='evolution')\n",
    "\n",
    "# 2. Shared type relationships\n",
    "print(\"Adding shared type relationships...\")\n",
    "type_groups = digimon_df.groupby('type')['name_en'].apply(list)\n",
    "for type_name, digimon_list in type_groups.items():\n",
    "    if len(digimon_list) > 1 and len(digimon_list) < 50:  # Avoid very large groups\n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, min(i + 6, len(digimon_list))):  # Limit connections\n",
    "                G.add_edge(digimon_list[i], digimon_list[j], \n",
    "                          weight=1.0, type='shared_type')\n",
    "\n",
    "# 3. Shared attribute relationships\n",
    "print(\"Adding shared attribute relationships...\")\n",
    "attr_groups = digimon_df.groupby('attribute')['name_en'].apply(list)\n",
    "for attr_name, digimon_list in attr_groups.items():\n",
    "    if len(digimon_list) > 1:\n",
    "        # Sample connections for large groups\n",
    "        if len(digimon_list) > 100:\n",
    "            sample_indices = np.random.choice(len(digimon_list), 100, replace=False)\n",
    "            digimon_list = [digimon_list[i] for i in sample_indices]\n",
    "        \n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, min(i + 4, len(digimon_list))):\n",
    "                if not G.has_edge(digimon_list[i], digimon_list[j]):\n",
    "                    G.add_edge(digimon_list[i], digimon_list[j], \n",
    "                              weight=0.5, type='shared_attribute')\n",
    "\n",
    "# 4. Shared moves relationships (sample)\n",
    "print(\"Adding shared move relationships...\")\n",
    "moves_df = conn.get_digimon_moves()\n",
    "move_groups = moves_df.groupby('move')['digimon'].apply(list)\n",
    "for move, digimon_list in move_groups.items():\n",
    "    if 2 <= len(digimon_list) <= 20:  # Moves shared by 2-20 Digimon\n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, len(digimon_list)):\n",
    "                if digimon_list[i] in G and digimon_list[j] in G:\n",
    "                    if G.has_edge(digimon_list[i], digimon_list[j]):\n",
    "                        G[digimon_list[i]][digimon_list[j]]['weight'] += 0.5\n",
    "                    else:\n",
    "                        G.add_edge(digimon_list[i], digimon_list[j], \n",
    "                                  weight=0.5, type='shared_move')\n",
    "\n",
    "print(f\"\\nGraph constructed:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Density: {nx.density(G):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove isolated nodes and get largest component\n",
    "isolated_nodes = list(nx.isolates(G))\n",
    "G.remove_nodes_from(isolated_nodes)\n",
    "print(f\"Removed {len(isolated_nodes)} isolated nodes\")\n",
    "\n",
    "# Get largest connected component\n",
    "components = list(nx.connected_components(G))\n",
    "largest_cc = max(components, key=len)\n",
    "G_main = G.subgraph(largest_cc).copy()\n",
    "\n",
    "print(f\"\\nLargest connected component:\")\n",
    "print(f\"  Nodes: {G_main.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G_main.number_of_edges()}\")\n",
    "print(f\"  Coverage: {G_main.number_of_nodes() / G.number_of_nodes():.1%} of non-isolated nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Community Detection Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Louvain Method\n",
    "print(\"=== LOUVAIN COMMUNITY DETECTION ===\")\n",
    "louvain_communities = detect_communities_louvain(G_main, resolution=1.0)\n",
    "louvain_modularity = calculate_modularity(G_main, louvain_communities)\n",
    "\n",
    "print(f\"Number of communities: {len(louvain_communities)}\")\n",
    "print(f\"Modularity score: {louvain_modularity:.3f}\")\n",
    "print(f\"\\nCommunity sizes:\")\n",
    "for comm_id, members in sorted(louvain_communities.items(), key=lambda x: len(x[1]), reverse=True)[:10]:\n",
    "    print(f\"  Community {comm_id}: {len(members)} members\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Label Propagation\n",
    "print(\"\\n=== LABEL PROPAGATION COMMUNITY DETECTION ===\")\n",
    "label_prop_communities = detect_communities_label_propagation(G_main)\n",
    "label_prop_modularity = calculate_modularity(G_main, label_prop_communities)\n",
    "\n",
    "print(f\"Number of communities: {len(label_prop_communities)}\")\n",
    "print(f\"Modularity score: {label_prop_modularity:.3f}\")\n",
    "print(f\"\\nTop community sizes:\")\n",
    "for comm_id, members in sorted(label_prop_communities.items(), key=lambda x: len(x[1]), reverse=True)[:10]:\n",
    "    print(f\"  Community {comm_id}: {len(members)} members\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Girvan-Newman (for smaller sample due to computational cost)\n",
    "print(\"\\n=== GIRVAN-NEWMAN COMMUNITY DETECTION ===\")\n",
    "# Sample a smaller subgraph\n",
    "sample_nodes = list(G_main.nodes())[:200]\n",
    "G_sample = G_main.subgraph(sample_nodes).copy()\n",
    "\n",
    "girvan_newman_communities = detect_communities_girvan_newman(G_sample, num_communities=8)\n",
    "girvan_newman_modularity = calculate_modularity(G_sample, girvan_newman_communities)\n",
    "\n",
    "print(f\"Number of communities: {len(girvan_newman_communities)}\")\n",
    "print(f\"Modularity score: {girvan_newman_modularity:.3f}\")\n",
    "print(f\"\\nCommunity sizes:\")\n",
    "for comm_id, members in girvan_newman_communities.items():\n",
    "    print(f\"  Community {comm_id}: {len(members)} members\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare algorithms\n",
    "algorithm_comparison = pd.DataFrame({\n",
    "    'Algorithm': ['Louvain', 'Label Propagation', 'Girvan-Newman (sample)'],\n",
    "    'Communities': [len(louvain_communities), len(label_prop_communities), len(girvan_newman_communities)],\n",
    "    'Modularity': [louvain_modularity, label_prop_modularity, girvan_newman_modularity],\n",
    "    'Avg Size': [\n",
    "        np.mean([len(c) for c in louvain_communities.values()]),\n",
    "        np.mean([len(c) for c in label_prop_communities.values()]),\n",
    "        np.mean([len(c) for c in girvan_newman_communities.values()])\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== ALGORITHM COMPARISON ===\")\n",
    "print(algorithm_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Community Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Louvain communities for detailed analysis\n",
    "communities = louvain_communities\n",
    "\n",
    "# Analyze community characteristics\n",
    "community_profiles = []\n",
    "\n",
    "for comm_id, members in communities.items():\n",
    "    # Get member attributes\n",
    "    member_data = digimon_df[digimon_df['name_en'].isin(members)]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    profile = {\n",
    "        'community_id': comm_id,\n",
    "        'size': len(members),\n",
    "        'density': nx.density(G_main.subgraph(members)),\n",
    "        'dominant_type': member_data['type'].mode().iloc[0] if len(member_data) > 0 else 'Unknown',\n",
    "        'dominant_attribute': member_data['attribute'].mode().iloc[0] if len(member_data) > 0 else 'Unknown',\n",
    "        'dominant_level': member_data['level'].mode().iloc[0] if len(member_data) > 0 else 'Unknown',\n",
    "        'type_diversity': member_data['type'].nunique(),\n",
    "        'attribute_diversity': member_data['attribute'].nunique(),\n",
    "        'level_diversity': member_data['level'].nunique()\n",
    "    }\n",
    "    \n",
    "    # Find central members\n",
    "    subgraph = G_main.subgraph(members)\n",
    "    if subgraph.number_of_nodes() > 0:\n",
    "        degree_cent = nx.degree_centrality(subgraph)\n",
    "        central_member = max(degree_cent.items(), key=lambda x: x[1])[0]\n",
    "        profile['central_member'] = central_member\n",
    "    \n",
    "    community_profiles.append(profile)\n",
    "\n",
    "community_df = pd.DataFrame(community_profiles)\n",
    "community_df = community_df.sort_values('size', ascending=False)\n",
    "\n",
    "print(\"=== TOP 10 COMMUNITIES BY SIZE ===\")\n",
    "print(community_df[['community_id', 'size', 'density', 'dominant_type', \n",
    "                   'dominant_attribute', 'central_member']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze inter-community connections\n",
    "inter_community_edges = defaultdict(int)\n",
    "\n",
    "# Create node to community mapping\n",
    "node_to_community = {}\n",
    "for comm_id, members in communities.items():\n",
    "    for member in members:\n",
    "        node_to_community[member] = comm_id\n",
    "\n",
    "# Count edges between communities\n",
    "for u, v in G_main.edges():\n",
    "    comm_u = node_to_community.get(u)\n",
    "    comm_v = node_to_community.get(v)\n",
    "    \n",
    "    if comm_u is not None and comm_v is not None and comm_u != comm_v:\n",
    "        edge_key = tuple(sorted([comm_u, comm_v]))\n",
    "        inter_community_edges[edge_key] += 1\n",
    "\n",
    "# Find most connected community pairs\n",
    "print(\"\\n=== STRONGEST INTER-COMMUNITY CONNECTIONS ===\")\n",
    "sorted_connections = sorted(inter_community_edges.items(), key=lambda x: x[1], reverse=True)\n",
    "for (comm1, comm2), edge_count in sorted_connections[:10]:\n",
    "    size1 = len(communities[comm1])\n",
    "    size2 = len(communities[comm2])\n",
    "    print(f\"Communities {comm1} (size {size1}) <-> {comm2} (size {size2}): {edge_count} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bridge nodes (high betweenness between communities)\n",
    "# Sample for efficiency\n",
    "sample_size = min(500, G_main.number_of_nodes())\n",
    "sample_nodes = list(G_main.nodes())[:sample_size]\n",
    "G_sample = G_main.subgraph(sample_nodes).copy()\n",
    "\n",
    "betweenness = nx.betweenness_centrality(G_sample)\n",
    "bridge_nodes = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "print(\"\\n=== BRIDGE NODES (High Betweenness) ===\")\n",
    "for node, centrality in bridge_nodes[:10]:\n",
    "    comm = node_to_community.get(node, 'Unknown')\n",
    "    node_data = digimon_df[digimon_df['name_en'] == node].iloc[0]\n",
    "    print(f\"{node} (Community {comm}, {node_data['type']}/{node_data['attribute']}): {centrality:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph embeddings using DeepWalk\n",
    "print(\"=== GRAPH EMBEDDINGS ===\")\n",
    "print(\"Generating DeepWalk embeddings...\")\n",
    "\n",
    "# Use smaller sample for embedding\n",
    "embedding_sample_size = min(300, G_main.number_of_nodes())\n",
    "embedding_nodes = list(G_main.nodes())[:embedding_sample_size]\n",
    "G_embedding = G_main.subgraph(embedding_nodes).copy()\n",
    "\n",
    "# Ensure nodes are labeled with integers for karateclub\n",
    "node_mapping = {node: i for i, node in enumerate(G_embedding.nodes())}\n",
    "reverse_mapping = {i: node for node, i in node_mapping.items()}\n",
    "\n",
    "G_int = nx.Graph()\n",
    "for u, v in G_embedding.edges():\n",
    "    G_int.add_edge(node_mapping[u], node_mapping[v])\n",
    "\n",
    "# Generate embeddings\n",
    "model = DeepWalk(dimensions=64, walk_length=10, walk_number=10)\n",
    "model.fit(G_int)\n",
    "embeddings = model.get_embedding()\n",
    "\n",
    "print(f\"Generated embeddings for {len(embeddings)} nodes\")\n",
    "print(f\"Embedding dimensions: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality for visualization\n",
    "print(\"\\nReducing dimensionality with t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame with embeddings and metadata\n",
    "embedding_df = pd.DataFrame({\n",
    "    'node': [reverse_mapping[i] for i in range(len(embeddings))],\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1]\n",
    "})\n",
    "\n",
    "# Add node attributes\n",
    "for idx, row in embedding_df.iterrows():\n",
    "    node_name = row['node']\n",
    "    node_attrs = G_embedding.nodes[node_name]\n",
    "    embedding_df.at[idx, 'type'] = node_attrs.get('type', 'Unknown')\n",
    "    embedding_df.at[idx, 'attribute'] = node_attrs.get('attribute', 'Unknown')\n",
    "    embedding_df.at[idx, 'level'] = node_attrs.get('level', 'Unknown')\n",
    "    embedding_df.at[idx, 'community'] = node_to_community.get(node_name, -1)\n",
    "\n",
    "print(\"Embedding visualization data prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster embeddings\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Determine optimal number of clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(3, 15)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(embeddings, labels))\n",
    "\n",
    "# Choose k with best silhouette score\n",
    "best_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal number of clusters (by silhouette score): {best_k}\")\n",
    "\n",
    "# Final clustering\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "embedding_clusters = kmeans.fit_predict(embeddings)\n",
    "embedding_df['embedding_cluster'] = embedding_clusters\n",
    "\n",
    "print(f\"Silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community size distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram of community sizes\n",
    "community_sizes = [len(members) for members in communities.values()]\n",
    "ax1.hist(community_sizes, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Community Size')\n",
    "ax1.set_ylabel('Number of Communities')\n",
    "ax1.set_title('Community Size Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Pie chart of top communities\n",
    "top_communities = community_df.head(10)\n",
    "other_size = sum(community_sizes) - top_communities['size'].sum()\n",
    "sizes = list(top_communities['size']) + [other_size]\n",
    "labels = [f\"Community {c}\" for c in top_communities['community_id']] + ['Others']\n",
    "\n",
    "ax2.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Community Size Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"community_size_analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community characteristics heatmap\n",
    "# Select top communities for visualization\n",
    "top_comm_df = community_df.head(15)\n",
    "\n",
    "# Create characteristic matrix\n",
    "char_matrix = top_comm_df[['type_diversity', 'attribute_diversity', 'level_diversity', 'density']].T\n",
    "char_matrix.columns = [f\"C{c}\" for c in top_comm_df['community_id']]\n",
    "\n",
    "# Normalize for better visualization\n",
    "char_matrix_norm = (char_matrix - char_matrix.min(axis=1).values.reshape(-1, 1)) / \\\n",
    "                   (char_matrix.max(axis=1).values.reshape(-1, 1) - char_matrix.min(axis=1).values.reshape(-1, 1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.heatmap(char_matrix_norm, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Normalized Value'}, ax=ax)\n",
    "ax.set_title('Community Characteristics Heatmap (Top 15)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Community')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"community_characteristics_heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# Plot by community\n",
    "scatter1 = axes[0, 0].scatter(embedding_df['x'], embedding_df['y'], \n",
    "                             c=embedding_df['community'], cmap='tab20', \n",
    "                             alpha=0.6, s=50)\n",
    "axes[0, 0].set_title('Graph Embeddings by Community', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('t-SNE 1')\n",
    "axes[0, 0].set_ylabel('t-SNE 2')\n",
    "\n",
    "# Plot by type\n",
    "type_colors = [TYPE_COLORS.get(t, '#808080') for t in embedding_df['type']]\n",
    "axes[0, 1].scatter(embedding_df['x'], embedding_df['y'], \n",
    "                   c=type_colors, alpha=0.6, s=50)\n",
    "axes[0, 1].set_title('Graph Embeddings by Type', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('t-SNE 1')\n",
    "axes[0, 1].set_ylabel('t-SNE 2')\n",
    "\n",
    "# Plot by attribute\n",
    "attr_colors = [ATTRIBUTE_COLORS.get(a, '#808080') for a in embedding_df['attribute']]\n",
    "axes[1, 0].scatter(embedding_df['x'], embedding_df['y'], \n",
    "                   c=attr_colors, alpha=0.6, s=50)\n",
    "axes[1, 0].set_title('Graph Embeddings by Attribute', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('t-SNE 1')\n",
    "axes[1, 0].set_ylabel('t-SNE 2')\n",
    "\n",
    "# Plot by embedding clusters\n",
    "scatter4 = axes[1, 1].scatter(embedding_df['x'], embedding_df['y'], \n",
    "                             c=embedding_df['embedding_cluster'], cmap='viridis', \n",
    "                             alpha=0.6, s=50)\n",
    "axes[1, 1].set_title('Graph Embeddings by Embedding Clusters', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('t-SNE 1')\n",
    "axes[1, 1].set_ylabel('t-SNE 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"graph_embeddings_visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-community connection matrix\n",
    "# Create adjacency matrix for communities\n",
    "num_communities = len(communities)\n",
    "comm_ids = sorted(communities.keys())\n",
    "comm_adjacency = np.zeros((num_communities, num_communities))\n",
    "\n",
    "for (comm1, comm2), count in inter_community_edges.items():\n",
    "    if comm1 in comm_ids and comm2 in comm_ids:\n",
    "        i = comm_ids.index(comm1)\n",
    "        j = comm_ids.index(comm2)\n",
    "        comm_adjacency[i, j] = count\n",
    "        comm_adjacency[j, i] = count\n",
    "\n",
    "# Visualize top communities only\n",
    "top_n = 20\n",
    "top_comm_ids = list(community_df.head(top_n)['community_id'])\n",
    "top_indices = [comm_ids.index(c) for c in top_comm_ids if c in comm_ids]\n",
    "top_adjacency = comm_adjacency[np.ix_(top_indices, top_indices)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(top_adjacency, xticklabels=top_comm_ids, yticklabels=top_comm_ids,\n",
    "            cmap='Blues', cbar_kws={'label': 'Number of Edges'}, ax=ax)\n",
    "ax.set_title('Inter-Community Connections (Top 20)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Community')\n",
    "ax.set_ylabel('Community')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"inter_community_connections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modularity comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "algorithms = algorithm_comparison['Algorithm']\n",
    "modularities = algorithm_comparison['Modularity']\n",
    "colors = sns.color_palette('Set2', len(algorithms))\n",
    "\n",
    "bars = ax.bar(algorithms, modularities, color=colors)\n",
    "ax.set_ylabel('Modularity Score')\n",
    "ax.set_title('Community Detection Algorithm Performance', fontsize=16, fontweight='bold')\n",
    "ax.set_ylim(0, max(modularities) * 1.1)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Add reference line\n",
    "ax.axhline(y=0.3, color='red', linestyle='--', alpha=0.5, label='Good modularity (>0.3)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"algorithm_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare export data\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_dir = Path('../results/data')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export community assignments\n",
    "community_assignments = []\n",
    "for node in G_main.nodes():\n",
    "    community_assignments.append({\n",
    "        'digimon': node,\n",
    "        'community': node_to_community.get(node, -1)\n",
    "    })\n",
    "\n",
    "assignments_df = pd.DataFrame(community_assignments)\n",
    "assignments_df.to_csv(results_dir / 'community_assignments.csv', index=False)\n",
    "\n",
    "# Export community profiles\n",
    "community_df.to_csv(results_dir / 'community_profiles.csv', index=False)\n",
    "\n",
    "# Export algorithm comparison\n",
    "algorithm_comparison.to_csv(results_dir / 'community_algorithm_comparison.csv', index=False)\n",
    "\n",
    "# Export embedding results\n",
    "embedding_df.to_csv(results_dir / 'graph_embeddings.csv', index=False)\n",
    "\n",
    "# Export summary statistics\n",
    "community_stats = {\n",
    "    'num_communities': len(communities),\n",
    "    'modularity': float(louvain_modularity),\n",
    "    'avg_community_size': float(np.mean(community_sizes)),\n",
    "    'largest_community_size': int(max(community_sizes)),\n",
    "    'smallest_community_size': int(min(community_sizes)),\n",
    "    'isolated_nodes_removed': len(isolated_nodes),\n",
    "    'graph_coverage': float(G_main.number_of_nodes() / len(digimon_df)),\n",
    "    'inter_community_edges': len(inter_community_edges),\n",
    "    'embedding_clusters': int(best_k),\n",
    "    'embedding_silhouette_score': float(max(silhouette_scores))\n",
    "}\n",
    "\n",
    "with open(results_dir / 'community_statistics.json', 'w') as f:\n",
    "    json.dump(community_stats, f, indent=2)\n",
    "\n",
    "print(\"Community detection results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Community Structure Insights:\n",
    "\n",
    "1. **Natural Groupings**:\n",
    "   - Clear community structure exists in the Digimon network\n",
    "   - Communities show good modularity scores (>0.3)\n",
    "   - Different algorithms largely agree on major communities\n",
    "\n",
    "2. **Community Characteristics**:\n",
    "   - Communities tend to share common types or attributes\n",
    "   - Some communities are evolution-based chains\n",
    "   - Others are based on shared characteristics (type/attribute)\n",
    "\n",
    "3. **Network Topology**:\n",
    "   - Scale-free distribution of community sizes\n",
    "   - Strong inter-community connections exist\n",
    "   - Bridge nodes connect different communities\n",
    "\n",
    "4. **Embedding Analysis**:\n",
    "   - Graph embeddings capture meaningful structure\n",
    "   - Embedding clusters align partially with communities\n",
    "   - Clear separation in embedding space by attributes\n",
    "\n",
    "These findings reveal the hierarchical and modular organization of the Digimon universe, with distinct groups formed by evolution, type affinity, and shared characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Community detection analysis complete! Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}