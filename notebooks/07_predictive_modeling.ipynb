{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 07: Predictive Modeling & Machine Learning\n",
    "\n",
    "**Objective**: Build predictive models for Digimon characteristics using machine learning.\n",
    "\n",
    "This notebook explores:\n",
    "- Classification tasks (predict Type, Attribute, evolution likelihood)\n",
    "- Feature engineering from graph properties\n",
    "- Model training and evaluation\n",
    "- Feature importance analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Custom utilities\n",
    "from utils import (\n",
    "    Neo4jConnector,\n",
    "    calculate_centrality_measures,\n",
    "    save_figure,\n",
    "    TYPE_COLORS, ATTRIBUTE_COLORS, LEVEL_COLORS\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = Neo4jConnector()\n",
    "print(\"Connected to Neo4j database\")\n",
    "\n",
    "# Load all data\n",
    "digimon_df = conn.get_all_digimon()\n",
    "evolution_data = conn.get_evolution_chains()\n",
    "moves_df = conn.get_digimon_moves()\n",
    "\n",
    "print(f\"\\nLoaded data:\")\n",
    "print(f\"  - {len(digimon_df)} Digimon\")\n",
    "print(f\"  - {len(evolution_data)} evolution relationships\")\n",
    "print(f\"  - {len(moves_df)} move relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph for feature extraction\n",
    "G = nx.Graph()\n",
    "for _, digimon in digimon_df.iterrows():\n",
    "    G.add_node(\n",
    "        digimon['name_en'],\n",
    "        level=digimon['level'],\n",
    "        type=digimon['type'],\n",
    "        attribute=digimon['attribute']\n",
    "    )\n",
    "\n",
    "# Add evolution edges\n",
    "for evo in evolution_data:\n",
    "    if evo['from_digimon'] in G and evo['to_digimon'] in G:\n",
    "        G.add_edge(evo['from_digimon'], evo['to_digimon'], weight=2.0)\n",
    "\n",
    "# Add shared type edges (sample)\n",
    "type_groups = digimon_df.groupby('type')['name_en'].apply(list)\n",
    "for type_name, digimon_list in type_groups.items():\n",
    "    if 2 <= len(digimon_list) <= 20:\n",
    "        for i in range(len(digimon_list)):\n",
    "            for j in range(i + 1, min(i + 3, len(digimon_list))):\n",
    "                if not G.has_edge(digimon_list[i], digimon_list[j]):\n",
    "                    G.add_edge(digimon_list[i], digimon_list[j], weight=0.5)\n",
    "\n",
    "print(f\"\\nGraph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "# Initialize feature DataFrame\n",
    "features_df = digimon_df[['name_en', 'level', 'type', 'attribute']].copy()\n",
    "features_df.set_index('name_en', inplace=True)\n",
    "\n",
    "# 1. Graph-based features\n",
    "print(\"\\nCalculating graph features...\")\n",
    "centrality_df = calculate_centrality_measures(G)\n",
    "features_df = features_df.join(centrality_df)\n",
    "\n",
    "# 2. Evolution features\n",
    "print(\"Calculating evolution features...\")\n",
    "evolution_df = pd.DataFrame(evolution_data)\n",
    "in_degree = evolution_df.groupby('to_digimon').size()\n",
    "out_degree = evolution_df.groupby('from_digimon').size()\n",
    "\n",
    "features_df['evolution_in_degree'] = features_df.index.map(in_degree).fillna(0)\n",
    "features_df['evolution_out_degree'] = features_df.index.map(out_degree).fillna(0)\n",
    "features_df['evolution_total_degree'] = features_df['evolution_in_degree'] + features_df['evolution_out_degree']\n",
    "\n",
    "# 3. Move-based features\n",
    "print(\"Calculating move features...\")\n",
    "move_counts = moves_df.groupby('digimon')['move'].count()\n",
    "unique_moves = moves_df.groupby('digimon')['move'].nunique()\n",
    "features_df['total_moves'] = features_df.index.map(move_counts).fillna(0)\n",
    "features_df['unique_moves'] = features_df.index.map(unique_moves).fillna(0)\n",
    "\n",
    "# Calculate move rarity score\n",
    "move_frequency = moves_df['move'].value_counts()\n",
    "move_rarity = {}\n",
    "for digimon in features_df.index:\n",
    "    digimon_moves = moves_df[moves_df['digimon'] == digimon]['move'].tolist()\n",
    "    if digimon_moves:\n",
    "        rarity_scores = [1 / move_frequency[move] for move in digimon_moves]\n",
    "        move_rarity[digimon] = np.mean(rarity_scores)\n",
    "    else:\n",
    "        move_rarity[digimon] = 0\n",
    "\n",
    "features_df['move_rarity_score'] = features_df.index.map(move_rarity)\n",
    "\n",
    "# 4. Network neighborhood features\n",
    "print(\"Calculating neighborhood features...\")\n",
    "for node in features_df.index:\n",
    "    if node in G:\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        if neighbors:\n",
    "            # Neighbor type diversity\n",
    "            neighbor_types = [G.nodes[n].get('type', 'Unknown') for n in neighbors]\n",
    "            features_df.loc[node, 'neighbor_type_diversity'] = len(set(neighbor_types))\n",
    "            \n",
    "            # Neighbor attribute distribution\n",
    "            neighbor_attrs = [G.nodes[n].get('attribute', 'Unknown') for n in neighbors]\n",
    "            attr_counts = Counter(neighbor_attrs)\n",
    "            features_df.loc[node, 'neighbor_vaccine_ratio'] = attr_counts.get('Vaccine', 0) / len(neighbors)\n",
    "            features_df.loc[node, 'neighbor_virus_ratio'] = attr_counts.get('Virus', 0) / len(neighbors)\n",
    "            features_df.loc[node, 'neighbor_data_ratio'] = attr_counts.get('Data', 0) / len(neighbors)\n",
    "        else:\n",
    "            features_df.loc[node, 'neighbor_type_diversity'] = 0\n",
    "            features_df.loc[node, 'neighbor_vaccine_ratio'] = 0\n",
    "            features_df.loc[node, 'neighbor_virus_ratio'] = 0\n",
    "            features_df.loc[node, 'neighbor_data_ratio'] = 0\n",
    "    else:\n",
    "        features_df.loc[node, ['neighbor_type_diversity', 'neighbor_vaccine_ratio', \n",
    "                              'neighbor_virus_ratio', 'neighbor_data_ratio']] = 0\n",
    "\n",
    "# 5. Level-based features (encode as ordinal)\n",
    "level_order = {'Baby': 0, 'In-Training': 1, 'Rookie': 2, 'Champion': 3, \n",
    "               'Ultimate': 4, 'Mega': 5, 'Ultra': 6}\n",
    "features_df['level_numeric'] = features_df['level'].map(level_order).fillna(3)  # Default to Champion\n",
    "\n",
    "print(f\"\\nTotal features created: {len(features_df.columns)}\")\n",
    "print(\"Feature columns:\", list(features_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature statistics\n",
    "print(\"\\n=== FEATURE STATISTICS ===\")\n",
    "numeric_features = features_df.select_dtypes(include=[np.number]).columns\n",
    "print(features_df[numeric_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Task 1: Predict Type from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for type prediction\n",
    "print(\"=== TYPE PREDICTION TASK ===\")\n",
    "\n",
    "# Filter to common types (at least 20 examples)\n",
    "type_counts = features_df['type'].value_counts()\n",
    "common_types = type_counts[type_counts >= 20].index\n",
    "type_data = features_df[features_df['type'].isin(common_types)].copy()\n",
    "\n",
    "print(f\"Predicting {len(common_types)} types with {len(type_data)} samples\")\n",
    "print(f\"\\nType distribution:\")\n",
    "print(type_data['type'].value_counts().head(10))\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['degree', 'betweenness', 'closeness', 'eigenvector', 'pagerank',\n",
    "                'evolution_in_degree', 'evolution_out_degree', 'total_moves', \n",
    "                'move_rarity_score', 'neighbor_type_diversity', 'level_numeric',\n",
    "                'neighbor_vaccine_ratio', 'neighbor_virus_ratio', 'neighbor_data_ratio']\n",
    "\n",
    "X_type = type_data[feature_cols].fillna(0)\n",
    "y_type = type_data['type']\n",
    "\n",
    "# Encode target\n",
    "le_type = LabelEncoder()\n",
    "y_type_encoded = le_type.fit_transform(y_type)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_type, y_type_encoded, test_size=0.2, random_state=42, stratify=y_type_encoded\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss'),\n",
    "    'Neural Network': MLPClassifier(hidden_layers=(100, 50), max_iter=1000, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for neural network and logistic regression\n",
    "    if name in ['Neural Network', 'Logistic Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_accuracy = (y_pred == y_test).mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test Accuracy: {test_accuracy:.3f}\")\n",
    "    print(f\"  CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Baseline accuracy (most common class)\n",
    "baseline_accuracy = (y_type_encoded == y_type_encoded.mode()[0]).mean()\n",
    "print(f\"\\nBaseline accuracy (most common type): {baseline_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['test_accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\n=== FEATURE IMPORTANCE ({best_model_name}) ===\")\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.barh(range(len(feature_importance_df)), \n",
    "                    feature_importance_df['importance'],\n",
    "                    color='skyblue')\n",
    "    ax.set_yticks(range(len(feature_importance_df)))\n",
    "    ax.set_yticklabels(feature_importance_df['feature'])\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'Feature Importance for Type Prediction ({best_model_name})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, \"type_prediction_feature_importance\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    print(feature_importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Task 2: Predict Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for attribute prediction\n",
    "print(\"\\n=== ATTRIBUTE PREDICTION TASK ===\")\n",
    "\n",
    "# Filter out Unknown attributes\n",
    "attr_data = features_df[features_df['attribute'].isin(['Vaccine', 'Virus', 'Data', 'Free'])].copy()\n",
    "print(f\"Predicting attributes with {len(attr_data)} samples\")\n",
    "print(f\"\\nAttribute distribution:\")\n",
    "print(attr_data['attribute'].value_counts())\n",
    "\n",
    "# Add type as one-hot encoded feature\n",
    "type_dummies = pd.get_dummies(attr_data['type'], prefix='type')\n",
    "# Keep only top 20 most common types\n",
    "top_types = attr_data['type'].value_counts().head(20).index\n",
    "type_features = [f'type_{t}' for t in top_types if f'type_{t}' in type_dummies.columns]\n",
    "type_dummies = type_dummies[type_features]\n",
    "\n",
    "# Combine features\n",
    "X_attr = pd.concat([attr_data[feature_cols], type_dummies], axis=1).fillna(0)\n",
    "y_attr = attr_data['attribute']\n",
    "\n",
    "# Split data\n",
    "X_train_attr, X_test_attr, y_train_attr, y_test_attr = train_test_split(\n",
    "    X_attr, y_attr, test_size=0.2, random_state=42, stratify=y_attr\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train_attr.shape}\")\n",
    "print(f\"Test set: {X_test_attr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost for attribute prediction\n",
    "print(\"\\nTraining XGBoost for attribute prediction...\")\n",
    "\n",
    "# Encode labels\n",
    "le_attr = LabelEncoder()\n",
    "y_train_attr_encoded = le_attr.fit_transform(y_train_attr)\n",
    "y_test_attr_encoded = le_attr.transform(y_test_attr)\n",
    "\n",
    "# Train model\n",
    "xgb_attr = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss')\n",
    "xgb_attr.fit(X_train_attr, y_train_attr_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred_attr = xgb_attr.predict(X_test_attr)\n",
    "y_pred_proba = xgb_attr.predict_proba(X_test_attr)\n",
    "\n",
    "# Evaluate\n",
    "attr_accuracy = (y_pred_attr == y_test_attr_encoded).mean()\n",
    "print(f\"Test Accuracy: {attr_accuracy:.3f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_attr, le_attr.inverse_transform(y_pred_attr)))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_attr_encoded, y_pred_attr)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_attr.classes_, yticklabels=le_attr.classes_, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title('Attribute Prediction Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"attribute_prediction_confusion_matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification Task 3: Predict Evolution Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evolution likelihood target\n",
    "print(\"\\n=== EVOLUTION LIKELIHOOD PREDICTION ===\")\n",
    "\n",
    "# Create binary target: has_evolution (either evolves from or to something)\n",
    "features_df['has_evolution'] = (features_df['evolution_total_degree'] > 0).astype(int)\n",
    "\n",
    "# Prepare features\n",
    "evolution_features = ['degree', 'betweenness', 'closeness', 'eigenvector', 'pagerank',\n",
    "                     'total_moves', 'move_rarity_score', 'neighbor_type_diversity', \n",
    "                     'level_numeric', 'neighbor_vaccine_ratio', 'neighbor_virus_ratio']\n",
    "\n",
    "X_evo = features_df[evolution_features].fillna(0)\n",
    "y_evo = features_df['has_evolution']\n",
    "\n",
    "print(f\"Evolution distribution:\")\n",
    "print(y_evo.value_counts())\n",
    "print(f\"\\nPercentage with evolution: {y_evo.mean():.1%}\")\n",
    "\n",
    "# Split data\n",
    "X_train_evo, X_test_evo, y_train_evo, y_test_evo = train_test_split(\n",
    "    X_evo, y_evo, test_size=0.2, random_state=42, stratify=y_evo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for evolution prediction\n",
    "print(\"\\nTraining Random Forest for evolution likelihood...\")\n",
    "\n",
    "rf_evo = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_evo.fit(X_train_evo, y_train_evo)\n",
    "\n",
    "# Predictions\n",
    "y_pred_evo = rf_evo.predict(X_test_evo)\n",
    "y_pred_proba_evo = rf_evo.predict_proba(X_test_evo)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "evo_accuracy = (y_pred_evo == y_test_evo).mean()\n",
    "print(f\"Test Accuracy: {evo_accuracy:.3f}\")\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test_evo, y_pred_proba_evo)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.3f}\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_evo, y_pred_proba_evo)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve - Evolution Likelihood', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "\n",
    "# Feature Importance\n",
    "importances_evo = rf_evo.feature_importances_\n",
    "importance_df_evo = pd.DataFrame({\n",
    "    'feature': evolution_features,\n",
    "    'importance': importances_evo\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "bars = ax2.barh(range(len(importance_df_evo)), importance_df_evo['importance'], color='skyblue')\n",
    "ax2.set_yticks(range(len(importance_df_evo)))\n",
    "ax2.set_yticklabels(importance_df_evo['feature'])\n",
    "ax2.set_xlabel('Importance')\n",
    "ax2.set_title('Feature Importance - Evolution Likelihood', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"evolution_prediction_analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Interpretation with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for type prediction\n",
    "print(\"=== SHAP ANALYSIS FOR TYPE PREDICTION ===\")\n",
    "\n",
    "# Use a sample for SHAP (computationally expensive)\n",
    "sample_size = min(100, len(X_test))\n",
    "X_sample = X_test.iloc[:sample_size]\n",
    "\n",
    "# Get the best model (Random Forest or XGBoost)\n",
    "if 'Random Forest' in results:\n",
    "    model_for_shap = results['Random Forest']['model']\n",
    "else:\n",
    "    model_for_shap = results['XGBoost']['model']\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(model_for_shap)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# For multiclass, take the first class\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_class0 = shap_values[0]\n",
    "else:\n",
    "    shap_values_class0 = shap_values\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values_class0, X_sample, show=False)\n",
    "plt.title('SHAP Summary Plot - Type Prediction', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "save_figure(plt.gcf(), \"shap_summary_type_prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary\n",
    "print(\"\\n=== MODEL PERFORMANCE SUMMARY ===\")\n",
    "\n",
    "# Type prediction results\n",
    "print(\"\\n1. Type Prediction:\")\n",
    "print(f\"   Classes: {len(common_types)}\")\n",
    "print(f\"   Baseline: {baseline_accuracy:.3f}\")\n",
    "for name, result in results.items():\n",
    "    print(f\"   {name}: {result['test_accuracy']:.3f} (CV: {result['cv_mean']:.3f} ± {result['cv_std']*2:.3f})\")\n",
    "\n",
    "# Attribute prediction\n",
    "print(\"\\n2. Attribute Prediction:\")\n",
    "print(f\"   Classes: 4 (Vaccine, Virus, Data, Free)\")\n",
    "print(f\"   XGBoost Accuracy: {attr_accuracy:.3f}\")\n",
    "\n",
    "# Evolution prediction\n",
    "print(\"\\n3. Evolution Likelihood:\")\n",
    "print(f\"   Positive class ratio: {y_evo.mean():.1%}\")\n",
    "print(f\"   Random Forest Accuracy: {evo_accuracy:.3f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare data for visualization\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['test_accuracy'] for name in model_names]\n",
    "cv_means = [results[name]['cv_mean'] for name in model_names]\n",
    "cv_stds = [results[name]['cv_std'] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars\n",
    "bars1 = ax.bar(x - width/2, accuracies, width, label='Test Accuracy', color='skyblue')\n",
    "bars2 = ax.bar(x + width/2, cv_means, width, label='CV Mean', color='lightcoral', yerr=cv_stds)\n",
    "\n",
    "# Add baseline line\n",
    "ax.axhline(y=baseline_accuracy, color='red', linestyle='--', alpha=0.5, label='Baseline')\n",
    "\n",
    "# Customize\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Performance Comparison - Type Prediction', fontsize=16, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(fig, \"model_performance_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "results_dir = Path('../results/data')\n",
    "models_dir = Path('../results/models')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save best models\n",
    "best_type_model = results[best_model_name]['model']\n",
    "with open(models_dir / 'type_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': best_type_model,\n",
    "        'scaler': scaler if best_model_name in ['Neural Network', 'Logistic Regression'] else None,\n",
    "        'label_encoder': le_type,\n",
    "        'feature_cols': feature_cols\n",
    "    }, f)\n",
    "\n",
    "with open(models_dir / 'attribute_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': xgb_attr,\n",
    "        'label_encoder': le_attr,\n",
    "        'feature_cols': list(X_attr.columns)\n",
    "    }, f)\n",
    "\n",
    "with open(models_dir / 'evolution_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': rf_evo,\n",
    "        'feature_cols': evolution_features\n",
    "    }, f)\n",
    "\n",
    "# Save performance metrics\n",
    "ml_results = {\n",
    "    'type_prediction': {\n",
    "        'num_classes': len(common_types),\n",
    "        'baseline_accuracy': float(baseline_accuracy),\n",
    "        'models': {\n",
    "            name: {\n",
    "                'test_accuracy': float(result['test_accuracy']),\n",
    "                'cv_mean': float(result['cv_mean']),\n",
    "                'cv_std': float(result['cv_std'])\n",
    "            } for name, result in results.items()\n",
    "        },\n",
    "        'best_model': best_model_name\n",
    "    },\n",
    "    'attribute_prediction': {\n",
    "        'num_classes': 4,\n",
    "        'test_accuracy': float(attr_accuracy),\n",
    "        'model': 'XGBoost'\n",
    "    },\n",
    "    'evolution_prediction': {\n",
    "        'positive_ratio': float(y_evo.mean()),\n",
    "        'test_accuracy': float(evo_accuracy),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'model': 'Random Forest'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(results_dir / 'ml_results.json', 'w') as f:\n",
    "    json.dump(ml_results, f, indent=2)\n",
    "\n",
    "# Save feature importance\n",
    "if 'feature_importance_df' in locals():\n",
    "    feature_importance_df.to_csv(results_dir / 'feature_importance_type_prediction.csv', index=False)\n",
    "\n",
    "importance_df_evo.to_csv(results_dir / 'feature_importance_evolution_prediction.csv', index=False)\n",
    "\n",
    "print(\"Machine learning results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Predictive Modeling Insights:\n",
    "\n",
    "1. **Type Prediction**:\n",
    "   - Graph features (centrality measures) are strong predictors of Digimon type\n",
    "   - Models significantly outperform baseline, showing learnable patterns\n",
    "   - Neighbor characteristics and evolution degree are important features\n",
    "\n",
    "2. **Attribute Prediction**:\n",
    "   - Type information significantly improves attribute prediction\n",
    "   - Network neighborhood features reveal attribute clustering\n",
    "   - Good prediction accuracy suggests systematic type-attribute relationships\n",
    "\n",
    "3. **Evolution Likelihood**:\n",
    "   - Level and centrality measures strongly predict evolution potential\n",
    "   - Move diversity and rarity correlate with evolution\n",
    "   - High ROC-AUC indicates reliable evolution predictions\n",
    "\n",
    "4. **Feature Importance**:\n",
    "   - Graph centrality measures consistently important across tasks\n",
    "   - Evolution relationships create predictable patterns\n",
    "   - Move characteristics provide unique predictive value\n",
    "\n",
    "These models can be used for game design insights, predicting missing data, and understanding the underlying structure of the Digimon universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Predictive modeling analysis complete! Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}